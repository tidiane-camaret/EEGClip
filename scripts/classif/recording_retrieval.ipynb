{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/test_env/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/jovyan/test_env/lib/python3.10/site-packages/braindecode/preprocessing/preprocess.py:55: UserWarning: Preprocessing choices with lambda functions cannot be saved.\n",
      "  warn('Preprocessing choices with lambda functions cannot be saved.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb subjects loaded :  2329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/test_env/lib/python3.10/site-packages/braindecode/preprocessing/windowers.py:608: UserWarning: Usage of offset_sample args in create_fixed_length_windows is deprecated and will be removed in future versions. Please use braindecode.preprocessing.preprocess.Preprocessor(\"crop\", tmin, tmax) instead.\n",
      "  warnings.warn('Usage of offset_sample args in create_fixed_length_windows is deprecated and'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/EEGClip/EEGClip/clip_models.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  embs_df[embs_name][r] = re\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 155\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;66;03m# ## Create model\u001b[39;00m\n\u001b[1;32m    154\u001b[0m eegclipmodel \u001b[38;5;241m=\u001b[39m EEGClipModel\u001b[38;5;241m.\u001b[39mload_from_checkpoint(EEGClip_config\u001b[38;5;241m.\u001b[39mmodel_paths[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meegclip\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m--> 155\u001b[0m \u001b[43meegclipmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m EEGEncoder \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mSequential(eegclipmodel\u001b[38;5;241m.\u001b[39meeg_encoder,eegclipmodel\u001b[38;5;241m.\u001b[39meeg_projection)\n\u001b[1;32m    157\u001b[0m \u001b[38;5;66;03m# get size of the last layer\u001b[39;00m\n",
      "File \u001b[0;32m~/test_env/lib/python3.10/site-packages/lightning_fabric/utilities/device_dtype_mixin.py:70\u001b[0m, in \u001b[0;36m_DeviceDtypeModuleMixin.cuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39m\"\"\"Moves all model parameters and buffers to the GPU. This also makes associated parameters and buffers\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39mdifferent objects. So it should be called before constructing optimizer if the module will live on GPU while\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[39mbeing optimized.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     67\u001b[0m \n\u001b[1;32m     68\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[39mif\u001b[39;00m device \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 70\u001b[0m     device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m, torch\u001b[39m.\u001b[39;49mcuda\u001b[39m.\u001b[39;49mcurrent_device())\n\u001b[1;32m     71\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(device, \u001b[39mint\u001b[39m):\n\u001b[1;32m     72\u001b[0m     device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m, index\u001b[39m=\u001b[39mdevice)\n",
      "File \u001b[0;32m~/test_env/lib/python3.10/site-packages/torch/cuda/__init__.py:552\u001b[0m, in \u001b[0;36mcurrent_device\u001b[0;34m()\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcurrent_device\u001b[39m() \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mint\u001b[39m:\n\u001b[1;32m    551\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Returns the index of a currently selected device.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 552\u001b[0m     _lazy_init()\n\u001b[1;32m    553\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_cuda_getDevice()\n",
      "File \u001b[0;32m~/test_env/lib/python3.10/site-packages/torch/cuda/__init__.py:229\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mCUDA_MODULE_LOADING\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39menviron:\n\u001b[1;32m    228\u001b[0m     os\u001b[39m.\u001b[39menviron[\u001b[39m'\u001b[39m\u001b[39mCUDA_MODULE_LOADING\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mLAZY\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 229\u001b[0m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_cuda_init()\n\u001b[1;32m    230\u001b[0m \u001b[39m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[39m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[39m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    233\u001b[0m _tls\u001b[39m.\u001b[39mis_initializing \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import socket\n",
    "import copy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch \n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import distance\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from braindecode.datasets.base import BaseConcatDataset\n",
    "from braindecode.datasets import TUHAbnormal\n",
    "from braindecode.preprocessing import create_fixed_length_windows\n",
    "from braindecode.util import set_random_seeds\n",
    "from braindecode.models.util import to_dense_prediction_model, get_output_shape\n",
    "from braindecode.datasets.tuh import TUHAbnormal\n",
    "from braindecode.preprocessing import preprocess, Preprocessor\n",
    "from braindecode.datasets.base import BaseConcatDataset\n",
    "from braindecode.preprocessing.windowers import create_fixed_length_windows\n",
    "from braindecode.models import Deep4Net\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from InstructorEmbedding import INSTRUCTOR\n",
    "\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "from EEGClip.classifier_models import EEGClassifierModel\n",
    "from EEGClip.clip_models import EEGClipModel\n",
    "from EEGClip.text_preprocessing import text_preprocessing\n",
    "\n",
    "import mne\n",
    "mne.set_log_level('ERROR')  # avoid messages everytime a window is extracted\n",
    "\n",
    "\n",
    "import EEGClip_config\n",
    "\n",
    "\"\"\"\n",
    "This script uses EEG-Clip representations to do recording retrieval :\n",
    "given a EEG segment, retrive the corresponding text description, and vice-versa\n",
    "metrics : median rank, recall@k\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "n_recordings_to_load = 2993\n",
    "\n",
    "\n",
    "n_max_minutes = 3\n",
    "sfreq = 100\n",
    "n_minutes = 2\n",
    "input_window_samples = 1200\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "nailcluster = (socket.gethostname() == \"vs3-0\")\n",
    "\n",
    "num_workers = 16\n",
    "\n",
    "results_dir = EEGClip_config.results_dir\n",
    "tuh_data_dir = EEGClip_config.tuh_data_dir\n",
    "\n",
    "# TODO : use get_output_shape (requires to load the model first)\n",
    "n_preds_per_input = 519 #get_output_shape(eeg_classifier_model, n_chans, input_window_samples)[2]\n",
    "\n",
    "\n",
    "seed = 20210325  # random seed to make results reproducible\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "set_random_seeds(seed=seed, cuda=cuda)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# ## Load data\n",
    "dataset = TUHAbnormal(\n",
    "    path=tuh_data_dir,\n",
    "    recording_ids=range(n_recordings_to_load),  # loads the n chronologically first recordings\n",
    "    target_name=\"report\",  # age, gender, pathology\n",
    "    preload=False,\n",
    "    add_physician_reports=True,\n",
    "    n_jobs=1)\n",
    "\n",
    "dataset.set_description(text_preprocessing(dataset.description, processed_categories = \"all\"), overwrite=True)\n",
    "\n",
    "# ## Preprocessing\n",
    "\n",
    "ar_ch_names = sorted([\n",
    "    'EEG A1-REF', 'EEG A2-REF',\n",
    "    'EEG FP1-REF', 'EEG FP2-REF', 'EEG F3-REF', 'EEG F4-REF', 'EEG C3-REF',\n",
    "    'EEG C4-REF', 'EEG P3-REF', 'EEG P4-REF', 'EEG O1-REF', 'EEG O2-REF',\n",
    "    'EEG F7-REF', 'EEG F8-REF', 'EEG T3-REF', 'EEG T4-REF', 'EEG T5-REF',\n",
    "    'EEG T6-REF', 'EEG FZ-REF', 'EEG CZ-REF', 'EEG PZ-REF'])\n",
    "\n",
    "preprocessors = [\n",
    "    Preprocessor(fn='pick_channels', ch_names=ar_ch_names, ordered=True),\n",
    "    Preprocessor('crop', tmin=0, tmax=n_max_minutes*60, include_tmax=True),\n",
    "    Preprocessor(fn=lambda x: np.clip(x, -800,800), apply_on_array=True),\n",
    "    Preprocessor('set_eeg_reference', ref_channels='average'),\n",
    "    # convert from volt to microvolt, directly modifying the numpy array\n",
    "    Preprocessor(fn=lambda x: x * 1e6, apply_on_array=True),\n",
    "    Preprocessor(fn=lambda x: x / 30, apply_on_array=True), # this seemed best\n",
    "    Preprocessor(fn='resample', sfreq=sfreq),\n",
    "]\n",
    "# Preprocess the data\n",
    "if not nailcluster:\n",
    "    preprocess(dataset, preprocessors)\n",
    "\n",
    "# ## Data Splitting\n",
    "# TODO : split using train and test splits instead\n",
    "# TODO : maybe load TUH now on top of TUH Abnormal ?\n",
    "\n",
    "\n",
    "#dataset = dataset.split('train')['True']\n",
    "\n",
    "n_subjects = len(dataset.split('subject'))\n",
    "\n",
    "print(\"Nb subjects loaded : \", n_subjects)\n",
    "\n",
    "valid_set = dataset.split('train')['False']\n",
    "\n",
    "\n",
    "window_valid_set = create_fixed_length_windows(\n",
    "    valid_set,\n",
    "    start_offset_samples=60*sfreq,\n",
    "    stop_offset_samples=60*sfreq+n_minutes*60*sfreq,\n",
    "    preload=True,\n",
    "    window_size_samples=input_window_samples,\n",
    "    window_stride_samples=n_preds_per_input,\n",
    "    drop_last_window=False,\n",
    ")\n",
    "\n",
    "### PREPROCESSING NECESSARY IF USING TUH_PRE\n",
    "if nailcluster:\n",
    "\n",
    "    window_valid_set.transform = lambda x: x*1e6\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "    window_valid_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False)\n",
    "\n",
    "print(len(valid_loader.dataset))\n",
    "\n",
    "\n",
    "# ## Create model\n",
    "\n",
    "eegclipmodel = EEGClipModel.load_from_checkpoint(EEGClip_config.model_paths[\"eegclip\"])\n",
    "eegclipmodel.cuda()\n",
    "EEGEncoder = torch.nn.Sequential(eegclipmodel.eeg_encoder,eegclipmodel.eeg_projection)\n",
    "# get size of the last layer\n",
    "text_encoder_name = \"medicalai/ClinicalBERT\"\n",
    "\n",
    "\n",
    "for param in EEGEncoder.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "embs_df = pd.read_csv(EEGClip_config.embs_df_path)\n",
    "embs_name = text_encoder_name\n",
    "for r in range(len(embs_df)):\n",
    "    re = copy.copy(embs_df[embs_name][r])\n",
    "    # convert the string to array\n",
    "    re = re.replace('[', '')\n",
    "    re = re.replace(']', '')\n",
    "    re = re.replace(',', '')\n",
    "    re = re.split()\n",
    "    re = [float(i) for i in re]\n",
    "    embs_df[embs_name][r] = re\n",
    "# iterate over the validation set and get the embeddings\n",
    "eeg_embs = []\n",
    "text_embs = []\n",
    "for batch in tqdm.tqdm(valid_loader):\n",
    "    eeg, text, id = batch\n",
    "    eeg = eeg.cuda()\n",
    "    eeg = EEGEncoder(eeg)\n",
    "    eeg = torch.mean(eeg, dim=2)\n",
    "    eeg_embs.append(eeg.detach().cpu().numpy())\n",
    "\n",
    "    text_emb = []\n",
    "    for s in text:\n",
    "        lookup = embs_df.loc[embs_df['report'] == s, text_encoder_name]\n",
    "        \n",
    "        emb = lookup.tolist()[0]\n",
    "        text_emb.append(emb)\n",
    "    text_emb = torch.Tensor(text_emb).to(device='cuda:0')\n",
    "    text_emb = eegclipmodel.text_projection(text_emb) #somehow, projecting the embeddings cause them to be unique \n",
    "    # (floating point precision ?) So we cannot use them to identify the recordings of each batch element (see below for that)\n",
    "    text_embs.append(text_emb.detach().cpu().numpy())\n",
    "\n",
    "\n",
    "eeg_embs = np.concatenate(eeg_embs)\n",
    "text_embs = np.concatenate(text_embs)\n",
    "\n",
    "print(eeg_embs.shape)\n",
    "print(text_embs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[263 263 263 ...   6   6   6]\n"
     ]
    }
   ],
   "source": [
    "# identify the recordings of each batch element \n",
    "t = []\n",
    "for batch in valid_loader:\n",
    "    eeg, text, id = batch\n",
    "    t.append(text)\n",
    "\n",
    "t = np.concatenate(t)\n",
    "\n",
    "\n",
    "e = []\n",
    "for s in t:\n",
    "        lookup = embs_df.loc[embs_df['report'] == s, text_encoder_name]\n",
    "        \n",
    "        emb = lookup.tolist()[0]\n",
    "        e.append(emb)\n",
    "\n",
    "n_recordings = eeg_embs.shape[0] \n",
    "unique_rows = np.unique(e, axis=0)\n",
    "\n",
    "# Get unique rows \n",
    "\n",
    "# Create mapping of recording index to unique ID\n",
    "rec_ids = np.zeros(n_recordings, dtype=int)\n",
    "for i, row in enumerate(e):\n",
    "    rec_ids[i] = np.where(np.all(unique_rows == row, axis=1))[0][0]\n",
    "\n",
    "print(rec_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6072"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rec_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient Retrieval Accuracy: 0.030467720685111988\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "n_recordings = eeg_embs.shape[0] \n",
    "\n",
    "retrieval_acc = []\n",
    "\n",
    "for i in range(n_recordings):\n",
    "\n",
    "  eeg_emb = eeg_embs[i]\n",
    "  true_id = rec_ids[i]\n",
    "\n",
    "  # Get embeddings for true patient  \n",
    "  true_indices = np.where(rec_ids == true_id)[0]\n",
    "  text_true = text_embs[true_indices]\n",
    "\n",
    "  sims = cosine_similarity(eeg_emb.reshape(1,-1), text_embs)[0]\n",
    "  retrieved_id = rec_ids[np.argmax(sims)]\n",
    "\n",
    "  correct = (retrieved_id == true_id)\n",
    "  retrieval_acc.append(correct)\n",
    "\n",
    "print(\"Accuracy for text retrieval:\", np.mean(retrieval_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median rank for text retrieval: 548.0\n"
     ]
    }
   ],
   "source": [
    "ranks = []\n",
    "for i in range(n_recordings):\n",
    "\n",
    "  eeg_emb = eeg_embs[i]\n",
    "  true_id = rec_ids[i]  \n",
    "\n",
    "  sims = cosine_similarity(eeg_emb.reshape(1,-1), text_embs)[0]\n",
    "  sorted_ids = rec_ids[np.argsort(sims)[::-1]]\n",
    "\n",
    "  true_idx = np.where(sorted_ids == true_id)[0][0]\n",
    "  ranks.append(true_idx + 1) \n",
    "\n",
    "median_rank = np.median(ranks)\n",
    "print(\"Median rank for text retrieval:\", median_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median rank for eeg retrieval: 166.0\n"
     ]
    }
   ],
   "source": [
    "ranks = []\n",
    "for i in range(n_recordings):\n",
    "\n",
    "  text_emb = text_embs[i]\n",
    "  true_id = rec_ids[i]  \n",
    "\n",
    "  sims = cosine_similarity(text_emb.reshape(1,-1), eeg_embs)[0]\n",
    "  sorted_ids = rec_ids[np.argsort(sims)[::-1]]\n",
    "\n",
    "  true_idx = np.where(sorted_ids == true_id)[0][0]\n",
    "  ranks.append(true_idx + 1) \n",
    "\n",
    "median_rank = np.median(ranks)\n",
    "print(\"Median rank for eeg retrieval:\", median_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_rec = len(np.unique(rec_ids))\n",
    "matrix_size = 10\n",
    "\"\"\"\n",
    "# Initialize random index vector  \n",
    "random_idx = np.zeros(num_patients, dtype=int)\n",
    "\n",
    "for i in range(num_patients):\n",
    "  \n",
    "  pid = rec_ids[i] \n",
    "  indices = np.where(rec_ids == pid)[0]\n",
    "  random_idx[i] = np.random.choice(indices)\n",
    "\n",
    "sim_matrix = np.zeros((num_patients, num_patients))\n",
    "\"\"\"\n",
    "random_idx = np.random.randint(len(rec_ids), size = matrix_size)\n",
    "#random_idx = range(matrix_size)\n",
    "\n",
    "sim_matrix = np.zeros((matrix_size,matrix_size))\n",
    "# Construct similarity matrix  \n",
    "\n",
    "\n",
    "for i in range(matrix_size):\n",
    "  eeg_idx = random_idx[i]\n",
    "  for j in range(matrix_size):\n",
    "    text_idx = random_idx[j]\n",
    "    \n",
    "    eeg1 = eeg_embs[eeg_idx].reshape(1,-1)\n",
    "    text2 = text_embs[text_idx].reshape(1,-1)  \n",
    "    sim = cosine_similarity(eeg1, text2)\n",
    "      \n",
    "    sim_matrix[i,j] = sim\n",
    "\n",
    "\n",
    "# Plot heatmap\n",
    "plt.matshow(sim_matrix)\n",
    "plt.colorbar() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median rank for eeg retrieval: 3.5\n",
      "Median rank for text retrieval: 3.5\n"
     ]
    }
   ],
   "source": [
    "ranks = []\n",
    "for i in range(matrix_size):\n",
    "  sims = sim_matrix[i,:]\n",
    "  sorted_ids = np.argsort(sims)[::-1]\n",
    "  true_idx = np.where(sorted_ids == i)[0][0]\n",
    "  ranks.append(true_idx + 1) \n",
    "median_rank = np.median(ranks)\n",
    "print(\"Median rank for eeg retrieval:\", median_rank)\n",
    "\n",
    "ranks = []\n",
    "for i in range(matrix_size):\n",
    "  sims = sim_matrix[:,i]\n",
    "  sorted_ids = np.argsort(sims)[::-1]\n",
    "  true_idx = np.where(sorted_ids == i)[0][0]\n",
    "  ranks.append(true_idx + 1) \n",
    "median_rank = np.median(ranks)\n",
    "print(\"Median rank for text retrieval:\", median_rank)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ndirt/miniconda3/envs/nail_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:2184: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5833333333333334"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "y_true = [0, 2, 0, 0, 7, 0]\n",
    "y_pred = [0, 2, 0, 0, 0, 1]\n",
    "balanced_accuracy_score(y_true, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nail_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
