{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/test_env/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/jovyan/test_env/lib/python3.10/site-packages/braindecode/preprocessing/preprocess.py:55: UserWarning: Preprocessing choices with lambda functions cannot be saved.\n",
      "  warn('Preprocessing choices with lambda functions cannot be saved.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb subjects loaded :  2329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/test_env/lib/python3.10/site-packages/braindecode/preprocessing/windowers.py:608: UserWarning: Usage of offset_sample args in create_fixed_length_windows is deprecated and will be removed in future versions. Please use braindecode.preprocessing.preprocess.Preprocessor(\"crop\", tmin, tmax) instead.\n",
      "  warnings.warn('Usage of offset_sample args in create_fixed_length_windows is deprecated and'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/EEGClip/EEGClip/clip_models.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  embs_df[embs_name][r] = re\n",
      "/tmp/ipykernel_16946/160036150.py:174: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  embs_df[embs_name][r] = re\n",
      "100%|██████████| 95/95 [00:05<00:00, 16.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6072, 64)\n",
      "(6072, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import socket\n",
    "import copy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch \n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import distance\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from braindecode.datasets.base import BaseConcatDataset\n",
    "from braindecode.datasets import TUHAbnormal\n",
    "from braindecode.preprocessing import create_fixed_length_windows\n",
    "from braindecode.util import set_random_seeds\n",
    "from braindecode.models.util import to_dense_prediction_model, get_output_shape\n",
    "from braindecode.datasets.tuh import TUHAbnormal\n",
    "from braindecode.preprocessing import preprocess, Preprocessor\n",
    "from braindecode.datasets.base import BaseConcatDataset\n",
    "from braindecode.preprocessing.windowers import create_fixed_length_windows\n",
    "from braindecode.models import Deep4Net\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from InstructorEmbedding import INSTRUCTOR\n",
    "\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "from EEGClip.classifier_models import EEGClassifierModel\n",
    "from EEGClip.clip_models import EEGClipModel\n",
    "from EEGClip.text_preprocessing import text_preprocessing\n",
    "\n",
    "import mne\n",
    "mne.set_log_level('ERROR')  # avoid messages everytime a window is extracted\n",
    "\n",
    "\n",
    "import EEGClip_config\n",
    "\n",
    "\"\"\"\n",
    "This script uses EEG-Clip representations to do recording retrieval :\n",
    "given a EEG segment, retrive the corresponding text description, and vice-versa\n",
    "metrics : median rank, recall@k\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "n_recordings_to_load = 2993\n",
    "\n",
    "\n",
    "n_max_minutes = 3\n",
    "sfreq = 100\n",
    "n_minutes = 2\n",
    "input_window_samples = 1200\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "nailcluster = (socket.gethostname() == \"vs3-0\")\n",
    "\n",
    "num_workers = 16\n",
    "\n",
    "results_dir = EEGClip_config.results_dir\n",
    "tuh_data_dir = EEGClip_config.tuh_data_dir\n",
    "\n",
    "# TODO : use get_output_shape (requires to load the model first)\n",
    "n_preds_per_input = 519 #get_output_shape(eeg_classifier_model, n_chans, input_window_samples)[2]\n",
    "\n",
    "\n",
    "seed = 20210325  # random seed to make results reproducible\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "set_random_seeds(seed=seed, cuda=cuda)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# ## Load data\n",
    "dataset = TUHAbnormal(\n",
    "    path=tuh_data_dir,\n",
    "    recording_ids=range(n_recordings_to_load),  # loads the n chronologically first recordings\n",
    "    target_name=\"report\",  # age, gender, pathology\n",
    "    preload=False,\n",
    "    add_physician_reports=True,\n",
    "    n_jobs=1)\n",
    "\n",
    "dataset.set_description(text_preprocessing(dataset.description, processed_categories = \"all\"), overwrite=True)\n",
    "\n",
    "# ## Preprocessing\n",
    "\n",
    "ar_ch_names = sorted([\n",
    "    'EEG A1-REF', 'EEG A2-REF',\n",
    "    'EEG FP1-REF', 'EEG FP2-REF', 'EEG F3-REF', 'EEG F4-REF', 'EEG C3-REF',\n",
    "    'EEG C4-REF', 'EEG P3-REF', 'EEG P4-REF', 'EEG O1-REF', 'EEG O2-REF',\n",
    "    'EEG F7-REF', 'EEG F8-REF', 'EEG T3-REF', 'EEG T4-REF', 'EEG T5-REF',\n",
    "    'EEG T6-REF', 'EEG FZ-REF', 'EEG CZ-REF', 'EEG PZ-REF'])\n",
    "\n",
    "preprocessors = [\n",
    "    Preprocessor(fn='pick_channels', ch_names=ar_ch_names, ordered=True),\n",
    "    Preprocessor('crop', tmin=0, tmax=n_max_minutes*60, include_tmax=True),\n",
    "    Preprocessor(fn=lambda x: np.clip(x, -800,800), apply_on_array=True),\n",
    "    Preprocessor('set_eeg_reference', ref_channels='average'),\n",
    "    # convert from volt to microvolt, directly modifying the numpy array\n",
    "    Preprocessor(fn=lambda x: x * 1e6, apply_on_array=True),\n",
    "    Preprocessor(fn=lambda x: x / 30, apply_on_array=True), # this seemed best\n",
    "    Preprocessor(fn='resample', sfreq=sfreq),\n",
    "]\n",
    "# Preprocess the data\n",
    "if not nailcluster:\n",
    "    preprocess(dataset, preprocessors)\n",
    "\n",
    "# ## Data Splitting\n",
    "# TODO : split using train and test splits instead\n",
    "# TODO : maybe load TUH now on top of TUH Abnormal ?\n",
    "\n",
    "\n",
    "#dataset = dataset.split('train')['True']\n",
    "\n",
    "n_subjects = len(dataset.split('subject'))\n",
    "\n",
    "print(\"Nb subjects loaded : \", n_subjects)\n",
    "\n",
    "valid_set = dataset.split('train')['False']\n",
    "\n",
    "\n",
    "window_valid_set = create_fixed_length_windows(\n",
    "    valid_set,\n",
    "    start_offset_samples=60*sfreq,\n",
    "    stop_offset_samples=60*sfreq+n_minutes*60*sfreq,\n",
    "    preload=True,\n",
    "    window_size_samples=input_window_samples,\n",
    "    window_stride_samples=n_preds_per_input,\n",
    "    drop_last_window=False,\n",
    ")\n",
    "\n",
    "### PREPROCESSING NECESSARY IF USING TUH_PRE\n",
    "if nailcluster:\n",
    "\n",
    "    window_valid_set.transform = lambda x: x*1e6\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "    window_valid_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False)\n",
    "\n",
    "print(len(valid_loader.dataset))\n",
    "\n",
    "\n",
    "# ## Create model\n",
    "\n",
    "eegclipmodel = EEGClipModel.load_from_checkpoint(EEGClip_config.model_paths[\"eegclip\"])\n",
    "eegclipmodel.cuda()\n",
    "EEGEncoder = torch.nn.Sequential(eegclipmodel.eeg_encoder,eegclipmodel.eeg_projection)\n",
    "# get size of the last layer\n",
    "text_encoder_name = \"medicalai/ClinicalBERT\"\n",
    "\n",
    "\n",
    "for param in EEGEncoder.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "embs_df = pd.read_csv(EEGClip_config.embs_df_path)\n",
    "embs_name = text_encoder_name\n",
    "for r in range(len(embs_df)):\n",
    "    re = copy.copy(embs_df[embs_name][r])\n",
    "    # convert the string to array\n",
    "    re = re.replace('[', '')\n",
    "    re = re.replace(']', '')\n",
    "    re = re.replace(',', '')\n",
    "    re = re.split()\n",
    "    re = [float(i) for i in re]\n",
    "    embs_df[embs_name][r] = re\n",
    "# iterate over the validation set and get the embeddings\n",
    "eeg_embs = []\n",
    "text_embs = []\n",
    "for batch in tqdm.tqdm(valid_loader):\n",
    "    eeg, text, id = batch\n",
    "    eeg = eeg.cuda()\n",
    "    eeg = EEGEncoder(eeg)\n",
    "    eeg = torch.mean(eeg, dim=2)\n",
    "    eeg_embs.append(eeg.detach().cpu().numpy())\n",
    "\n",
    "    text_emb = []\n",
    "    for s in text:\n",
    "        lookup = embs_df.loc[embs_df['report'] == s, text_encoder_name]\n",
    "        \n",
    "        emb = lookup.tolist()[0]\n",
    "        text_emb.append(emb)\n",
    "    text_emb = torch.Tensor(text_emb).to(device='cuda:0')\n",
    "    text_emb = eegclipmodel.text_projection(text_emb)\n",
    "    text_embs.append(text_emb.detach().cpu().numpy())\n",
    "\n",
    "\n",
    "eeg_embs = np.concatenate(eeg_embs)\n",
    "text_embs = np.concatenate(text_embs)\n",
    "\n",
    "print(eeg_embs.shape)\n",
    "print(text_embs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median rank: 864.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "n_recordings = eeg_embs.shape[0] \n",
    "\n",
    "ranks = []\n",
    "for i in range(n_recordings):\n",
    "  eeg_emb = eeg_embs[i]\n",
    "  \n",
    "  sims = cosine_similarity(eeg_emb.reshape(1,-1), text_embs)[0] \n",
    "  sorted_sims = np.argsort(sims)[::-1]\n",
    "  \n",
    "  true_idx = np.where(sorted_sims == i)[0][0]\n",
    "  ranks.append(true_idx + 1)\n",
    "  \n",
    "median_rank = np.median(ranks)\n",
    "print(\"Median rank:\", median_rank)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "097b7033baff6ef61c19d5e3b26d00f2edd9fddb86c25af544d86fb0636b8d9f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
