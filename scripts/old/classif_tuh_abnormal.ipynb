{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /home/jovyan/mne_data/TUH/tuh_eeg_abnormal/v2.0.0/edf/eval/normal/01_tcp_ar/058/00005864/s001_2009_09_03/00005864_s001_t000.edf...\n",
      "EDF file detected\n",
      "Extracting EDF parameters from /home/jovyan/mne_data/TUH/tuh_eeg_abnormal/v2.0.0/edf/eval/normal/01_tcp_ar/041/00004196/s003_2009_09_03/00004196_s003_t000.edf...\n",
      "EDF file detected\n",
      "Extracting EDF parameters from /home/jovyan/mne_data/TUH/tuh_eeg_abnormal/v2.0.0/edf/train/normal/01_tcp_ar/009/00000929/s003_2009_09_04/00000929_s003_t002.edf...\n",
      "EDF file detected\n",
      "Extracting EDF parameters from /home/jovyan/mne_data/TUH/tuh_eeg_abnormal/v2.0.0/edf/eval/normal/01_tcp_ar/062/00006201/s001_2009_09_10/00006201_s001_t000.edf...\n",
      "EDF file detected\n",
      "Extracting EDF parameters from /home/jovyan/mne_data/TUH/tuh_eeg_abnormal/v2.0.0/edf/eval/normal/01_tcp_ar/058/00005851/s001_2009_09_04/00005851_s001_t001.edf...\n",
      "Setting channel info structure...\n",
      "EDF file detected\n",
      "Extracting EDF parameters from /home/jovyan/mne_data/TUH/tuh_eeg_abnormal/v2.0.0/edf/train/normal/01_tcp_ar/059/00005909/s002_2009_09_09/00005909_s002_t000.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Extracting EDF parameters from /home/jovyan/mne_data/TUH/tuh_eeg_abnormal/v2.0.0/edf/eval/normal/01_tcp_ar/064/00006422/s001_2009_09_10/00006422_s001_t000.edf...\n",
      "EDF file detected\n",
      "Creating raw.info structure...\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from /home/jovyan/mne_data/TUH/tuh_eeg_abnormal/v2.0.0/edf/train/abnormal/01_tcp_ar/059/00005928/s001_2009_09_11/00005928_s001_t000.edf...\n",
      "EDF file detected\n",
      "Creating raw.info structure...\n",
      "Setting channel info structure...\n",
      "Setting channel info structure...\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Creating raw.info structure...\n",
      "Setting channel info structure...\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Creating raw.info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from /home/jovyan/mne_data/TUH/tuh_eeg_abnormal/v2.0.0/edf/eval/abnormal/01_tcp_ar/045/00004526/s003_2009_09_15/00004526_s003_t001.edf...\n",
      "EDF file detected\n",
      "Extracting EDF parameters from /home/jovyan/mne_data/TUH/tuh_eeg_abnormal/v2.0.0/edf/eval/normal/01_tcp_ar/059/00005921/s001_2009_09_15/00005921_s001_t000.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "length of dataset :  4125500\n",
      "x: [[3.5e-09]\n",
      " [3.5e-09]\n",
      " [3.5e-09]\n",
      " [3.5e-09]\n",
      " [3.5e-09]\n",
      " [3.5e-09]\n",
      " [3.5e-09]\n",
      " [3.5e-09]\n",
      " [3.5e-09]\n",
      " [3.5e-09]\n",
      " [3.5e-09]\n",
      " [3.5e-09]\n",
      " [3.5e-09]\n",
      " [3.5e-09]\n",
      " [3.5e-09]\n",
      " [3.5e-09]\n",
      " [3.5e-09]\n",
      " [3.5e-09]\n",
      " [3.5e-09]\n",
      " [3.5e-09]\n",
      " [3.5e-09]\n",
      " [3.5e-09]\n",
      " [3.5e-09]\n",
      " [3.5e-09]\n",
      " [3.5e-09]\n",
      " [3.5e-09]\n",
      " [3.5e-09]\n",
      " [3.5e-09]\n",
      " [3.5e-09]\n",
      " [3.5e-09]\n",
      " [3.5e-09]\n",
      " [3.5e-09]\n",
      " [0.0e+00]\n",
      " [0.0e+00]\n",
      " [0.0e+00]\n",
      " [0.0e+00]]\n",
      "y: DESCRIPTION OF THE RECORD:  In wakefulness background EEG is well-organized. There is a relatively fast alpha rhythm of 12 Hz with a small amount of low voltage, frontocentral beta. Hyperventilation produces an increased in amplitude of the background. This is followed by a drowsy and then stage I sleep with vertex waves and posts. Photic stimulation and hyperventilation are performed concurrently and do not active the record. In fact, the patient seems to drift into stage II sleep at the close of this study.\n",
      "HR: \t66 bpm\n",
      "IMPRESSION: Normal EEG.\n",
      "CLINICAL CORRELATION: No focal nor epileptiform features are observed. Normal\n",
      "EEG does not exclude a diagnosis of epilepsy.\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "import pandas as pd\n",
    "from braindecode.datasets import TUHAbnormal\n",
    "from braindecode.preprocessing import (\n",
    "    preprocess, Preprocessor, create_fixed_length_windows, create_windows_from_events, scale as multiply)\n",
    "import torch\n",
    "from braindecode.util import set_random_seeds\n",
    "from braindecode.models import ShallowFBCSPNet\n",
    "\n",
    "mne.set_log_level('ERROR')  # avoid messages everytime a window is extracted\n",
    "\n",
    "TUH_PATH = '/home/jovyan/mne_data/TUH/tuh_eeg_abnormal/v2.0.0'\n",
    "N_JOBS = 8  # specify the number of jobs for loading and windowing\n",
    "N_SAMPLES = 10\n",
    "\n",
    "tuh = TUHAbnormal(\n",
    "    path=TUH_PATH,\n",
    "    recording_ids=list(range(N_SAMPLES)),\n",
    "    target_name=('report'),#'pathological'),\n",
    "    preload=False,\n",
    "    add_physician_reports=True,\n",
    "    n_jobs=N_JOBS,  # Mock dataset can't\n",
    "    # be loaded in parallel\n",
    ")\n",
    "\n",
    "print(\"length of dataset : \", len(tuh))\n",
    "\n",
    "#show last example \n",
    "x, y = tuh[-1]\n",
    "print('x:', x)\n",
    "print('y:', y[y.find('DESCRIPTION OF THE RECORD:'):])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                path  year  month  day  \\\n",
      "0  /home/jovyan/mne_data/TUH/tuh_eeg_abnormal/v2....  2009      9    3   \n",
      "1  /home/jovyan/mne_data/TUH/tuh_eeg_abnormal/v2....  2009      9    3   \n",
      "2  /home/jovyan/mne_data/TUH/tuh_eeg_abnormal/v2....  2009      9    4   \n",
      "3  /home/jovyan/mne_data/TUH/tuh_eeg_abnormal/v2....  2009      9    4   \n",
      "4  /home/jovyan/mne_data/TUH/tuh_eeg_abnormal/v2....  2009      9    9   \n",
      "5  /home/jovyan/mne_data/TUH/tuh_eeg_abnormal/v2....  2009      9   10   \n",
      "6  /home/jovyan/mne_data/TUH/tuh_eeg_abnormal/v2....  2009      9   10   \n",
      "7  /home/jovyan/mne_data/TUH/tuh_eeg_abnormal/v2....  2009      9   11   \n",
      "8  /home/jovyan/mne_data/TUH/tuh_eeg_abnormal/v2....  2009      9   15   \n",
      "9  /home/jovyan/mne_data/TUH/tuh_eeg_abnormal/v2....  2009      9   15   \n",
      "\n",
      "   subject  session  segment  age gender  \\\n",
      "0     4196        3        0   53      F   \n",
      "1     5864        1        0   30      M   \n",
      "2      929        3        2   39      F   \n",
      "3     5851        1        1   65      F   \n",
      "4     5909        2        0   32      M   \n",
      "5     6201        1        0   54      M   \n",
      "6     6422        1        0   50      M   \n",
      "7     5928        1        0   70      F   \n",
      "8     4526        3        1   71      F   \n",
      "9     5921        1        0   39      F   \n",
      "\n",
      "                                              report version  train  \\\n",
      "0  CLINICAL HISTORY:  Seizures.\\nMEDICATIONS: Dil...  v2.0.0  False   \n",
      "1  CLINICAL HISTORY: Schizophrenia, memory loss.\\...  v2.0.0  False   \n",
      "2  CLINICAL HISTORY:  Epilepsy, currently seizure...  v2.0.0   True   \n",
      "3  CLINICAL HISTORY:  Sixty-five-year-old woman w...  v2.0.0  False   \n",
      "4  CLINICAL HISTORY: 32 year old male with episod...  v2.0.0   True   \n",
      "5  CLINICAL HISTORY: 54 year old male with recurr...  v2.0.0  False   \n",
      "6  \\nCLINICAL HISTORY:   49 year old left handed ...  v2.0.0  False   \n",
      "7  CLINICAL HISTORY:  71 year old woman with recu...  v2.0.0   True   \n",
      "8  \\nCLINICAL HISTORY: 71 year old woman with epi...  v2.0.0  False   \n",
      "9  CLINICAL HISTORY:    38 year old right handed ...  v2.0.0  False   \n",
      "\n",
      "   pathological  \n",
      "0         False  \n",
      "1         False  \n",
      "2         False  \n",
      "3         False  \n",
      "4         False  \n",
      "5         False  \n",
      "6         False  \n",
      "7          True  \n",
      "8          True  \n",
      "9         False  \n"
     ]
    }
   ],
   "source": [
    "print(tuh.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for 351 events and 1000 original time points ...\n",
      "Loading data for 297 events and 1000 original time points ...\n",
      "Loading data for 287 events and 1000 original time points ...\n",
      "Loading data for 756 events and 1000 original time points ...\n",
      "Loading data for 753 events and 1000 original time points ...\n",
      "Loading data for 366 events and 1000 original time points ...\n",
      "Loading data for 384 events and 1000 original time points ...\n",
      "Loading data for 312 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Loading data for 322 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Loading data for 301 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "0 bad epochs dropped\n",
      "0 bad epochs dropped\n",
      "0 bad epochs dropped\n",
      "0 bad epochs dropped\n",
      "0 bad epochs dropped\n",
      "0 bad epochs dropped\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "# create windows\n",
    "\n",
    "window_size_samples = 1000\n",
    "window_stride_samples = 1000\n",
    "tuh_windows = create_fixed_length_windows(\n",
    "    tuh,\n",
    "    window_size_samples=window_size_samples,\n",
    "    window_stride_samples=window_stride_samples,\n",
    "    drop_last_window=False,\n",
    "    n_jobs=N_JOBS,\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4129"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tuh_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "splitted = tuh_windows.split(\"train\")\n",
    "train_set = splitted['True']\n",
    "valid_set = splitted['False']\n",
    "\n",
    "cuda = False #torch.cuda.is_available()  # check if GPU is available, if True chooses to use it\n",
    "device = 'cuda' if cuda else 'cpu'\n",
    "if cuda:\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "seed = 20200220\n",
    "set_random_seeds(seed=seed, cuda=cuda)\n",
    "\n",
    "n_classes = 2\n",
    "# Extract number of chans and time steps from dataset\n",
    "n_chans = train_set[0][0].shape[0]\n",
    "input_window_samples = train_set[0][0].shape[1]\n",
    "\n",
    "model = ShallowFBCSPNet(\n",
    "    n_chans,\n",
    "    n_classes,\n",
    "    input_window_samples=input_window_samples,\n",
    "    final_conv_length='auto',\n",
    ")\n",
    "\n",
    "# Send model to GPU\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "\n",
    "\n",
    "# These values we found good for shallow network:\n",
    "lr = 0.0625 * 0.01\n",
    "weight_decay = 0\n",
    "\n",
    "# For deep4 they should be:\n",
    "# lr = 1 * 0.01\n",
    "# weight_decay = 0.5 * 0.001\n",
    "\n",
    "batch_size = 64\n",
    "n_epochs = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nfrom skorch.callbacks import LRScheduler\\nfrom skorch.helper import predefined_split\\n\\nfrom braindecode import EEGClassifier\\nclf = EEGClassifier(\\n    model,\\n    criterion=torch.nn.NLLLoss,\\n    optimizer=torch.optim.AdamW,\\n    train_split=predefined_split(valid_set),  # using valid_set for validation\\n    optimizer__lr=lr,\\n    optimizer__weight_decay=weight_decay,\\n    batch_size=batch_size,\\n    callbacks=[\\n        \"accuracy\", (\"lr_scheduler\", LRScheduler(\\'CosineAnnealingLR\\', T_max=n_epochs - 1)),\\n    ],\\n    device=device,\\n)\\n# Model training for a specified number of epochs. `y` is None as it is already supplied\\n# in the dataset.\\nclf.fit(train_set, y=None, epochs=n_epochs)\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use EEGClassifier class for training\n",
    "\"\"\"\n",
    "\n",
    "from skorch.callbacks import LRScheduler\n",
    "from skorch.helper import predefined_split\n",
    "\n",
    "from braindecode import EEGClassifier\n",
    "clf = EEGClassifier(\n",
    "    model,\n",
    "    criterion=torch.nn.NLLLoss,\n",
    "    optimizer=torch.optim.AdamW,\n",
    "    train_split=predefined_split(valid_set),  # using valid_set for validation\n",
    "    optimizer__lr=lr,\n",
    "    optimizer__weight_decay=weight_decay,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=[\n",
    "        \"accuracy\", (\"lr_scheduler\", LRScheduler('CosineAnnealingLR', T_max=n_epochs - 1)),\n",
    "    ],\n",
    "    device=device,\n",
    ")\n",
    "# Model training for a specified number of epochs. `y` is None as it is already supplied\n",
    "# in the dataset.\n",
    "clf.fit(train_set, y=None, epochs=n_epochs)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use pytorch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "dl = torch.utils.data.DataLoader(\n",
    "    dataset=tuh_windows,\n",
    "    batch_size=4,\n",
    ")\n",
    "\n",
    "loss_fn = torch.nn.NLLLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4]) torch.Size([4, 2])\n",
      "tensor(33.8681, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([4]) torch.Size([4, 2])\n",
      "tensor(0., grad_fn=<NllLossBackward0>)\n",
      "torch.Size([4]) torch.Size([4, 2])\n",
      "tensor(0., grad_fn=<NllLossBackward0>)\n",
      "torch.Size([4]) torch.Size([4, 2])\n",
      "tensor(0., grad_fn=<NllLossBackward0>)\n",
      "torch.Size([4]) torch.Size([4, 2])\n",
      "tensor(0., grad_fn=<NllLossBackward0>)\n",
      "torch.Size([4]) torch.Size([4, 2])\n",
      "tensor(0., grad_fn=<NllLossBackward0>)\n",
      "torch.Size([4]) torch.Size([4, 2])\n",
      "tensor(7.1526e-07, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([4]) torch.Size([4, 2])\n",
      "tensor(1.1206e-05, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([4]) torch.Size([4, 2])\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([4]) torch.Size([4, 2])\n",
      "tensor(0.6835, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([4]) torch.Size([4, 2])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [44], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m      9\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 10\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(loss)\n",
      "File \u001b[0;32m~/test_env/lib/python3.10/site-packages/torch/optim/optimizer.py:140\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 140\u001b[0m     out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     obj\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/test_env/lib/python3.10/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/test_env/lib/python3.10/site-packages/torch/optim/adamw.py:162\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    158\u001b[0m             max_exp_avg_sqs\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mmax_exp_avg_sq\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m    160\u001b[0m         state_steps\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mstep\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m--> 162\u001b[0m     adamw(params_with_grad,\n\u001b[1;32m    163\u001b[0m           grads,\n\u001b[1;32m    164\u001b[0m           exp_avgs,\n\u001b[1;32m    165\u001b[0m           exp_avg_sqs,\n\u001b[1;32m    166\u001b[0m           max_exp_avg_sqs,\n\u001b[1;32m    167\u001b[0m           state_steps,\n\u001b[1;32m    168\u001b[0m           amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[1;32m    169\u001b[0m           beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    170\u001b[0m           beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    171\u001b[0m           lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    172\u001b[0m           weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    173\u001b[0m           eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    174\u001b[0m           maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    175\u001b[0m           foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    176\u001b[0m           capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m    178\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/test_env/lib/python3.10/site-packages/torch/optim/adamw.py:219\u001b[0m, in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    217\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adamw\n\u001b[0;32m--> 219\u001b[0m func(params,\n\u001b[1;32m    220\u001b[0m      grads,\n\u001b[1;32m    221\u001b[0m      exp_avgs,\n\u001b[1;32m    222\u001b[0m      exp_avg_sqs,\n\u001b[1;32m    223\u001b[0m      max_exp_avg_sqs,\n\u001b[1;32m    224\u001b[0m      state_steps,\n\u001b[1;32m    225\u001b[0m      amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[1;32m    226\u001b[0m      beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    227\u001b[0m      beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    228\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    229\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m    230\u001b[0m      eps\u001b[39m=\u001b[39;49meps,\n\u001b[1;32m    231\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[1;32m    232\u001b[0m      capturable\u001b[39m=\u001b[39;49mcapturable)\n",
      "File \u001b[0;32m~/test_env/lib/python3.10/site-packages/torch/optim/adamw.py:318\u001b[0m, in \u001b[0;36m_single_tensor_adamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    316\u001b[0m     denom \u001b[39m=\u001b[39m (exp_avg_sq\u001b[39m.\u001b[39msqrt() \u001b[39m/\u001b[39m bias_correction2_sqrt)\u001b[39m.\u001b[39madd_(eps)\n\u001b[0;32m--> 318\u001b[0m param\u001b[39m.\u001b[39;49maddcdiv_(exp_avg, denom, value\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49mstep_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for x, y, z in dl:\n",
    "    #print(\"x : \",x)\n",
    "    x.to(device)\n",
    "    y.to(device)\n",
    "    y_hat = model(x)\n",
    "    print(y.shape, y_hat.shape)\n",
    "    loss = loss_fn(y_hat, y.long())\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(loss)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "097b7033baff6ef61c19d5e3b26d00f2edd9fddb86c25af544d86fb0636b8d9f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
