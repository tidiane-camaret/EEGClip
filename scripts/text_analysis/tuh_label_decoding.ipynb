{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/test_env/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from braindecode.datasets import TUHAbnormal\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from InstructorEmbedding import INSTRUCTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of T5Model were not initialized from the model checkpoint at hkunlp/instructor-xl and are newly initialized: ['decoder.block.12.layer.0.layer_norm.weight', 'decoder.block.23.layer.1.EncDecAttention.k.weight', 'decoder.block.17.layer.1.EncDecAttention.v.weight', 'decoder.block.14.layer.1.EncDecAttention.o.weight', 'decoder.block.18.layer.0.SelfAttention.o.weight', 'decoder.block.23.layer.1.layer_norm.weight', 'decoder.block.23.layer.2.DenseReluDense.wo.weight', 'decoder.block.12.layer.1.EncDecAttention.k.weight', 'decoder.block.5.layer.0.SelfAttention.k.weight', 'decoder.block.2.layer.2.DenseReluDense.wi.weight', 'decoder.block.3.layer.0.SelfAttention.o.weight', 'decoder.block.21.layer.0.SelfAttention.q.weight', 'decoder.block.22.layer.1.EncDecAttention.o.weight', 'decoder.block.13.layer.2.layer_norm.weight', 'decoder.block.16.layer.2.DenseReluDense.wo.weight', 'decoder.block.9.layer.1.layer_norm.weight', 'decoder.block.13.layer.0.SelfAttention.q.weight', 'decoder.block.22.layer.0.SelfAttention.q.weight', 'decoder.block.3.layer.2.DenseReluDense.wi.weight', 'decoder.block.4.layer.0.SelfAttention.k.weight', 'decoder.block.8.layer.2.layer_norm.weight', 'decoder.block.3.layer.2.DenseReluDense.wo.weight', 'decoder.block.6.layer.1.EncDecAttention.q.weight', 'decoder.block.8.layer.1.EncDecAttention.v.weight', 'decoder.block.21.layer.2.DenseReluDense.wo.weight', 'decoder.block.4.layer.2.DenseReluDense.wi.weight', 'decoder.block.19.layer.1.EncDecAttention.o.weight', 'decoder.block.22.layer.0.SelfAttention.k.weight', 'decoder.block.23.layer.1.EncDecAttention.q.weight', 'decoder.block.15.layer.1.layer_norm.weight', 'decoder.block.4.layer.2.DenseReluDense.wo.weight', 'decoder.block.16.layer.0.SelfAttention.o.weight', 'decoder.block.16.layer.1.EncDecAttention.v.weight', 'decoder.block.4.layer.1.layer_norm.weight', 'decoder.block.9.layer.0.layer_norm.weight', 'decoder.block.23.layer.0.SelfAttention.k.weight', 'decoder.block.3.layer.1.EncDecAttention.o.weight', 'decoder.block.11.layer.0.SelfAttention.k.weight', 'decoder.block.17.layer.1.EncDecAttention.o.weight', 'decoder.block.5.layer.1.layer_norm.weight', 'decoder.block.19.layer.0.layer_norm.weight', 'decoder.block.7.layer.0.SelfAttention.q.weight', 'decoder.block.9.layer.2.DenseReluDense.wo.weight', 'decoder.block.21.layer.0.SelfAttention.v.weight', 'decoder.block.6.layer.2.layer_norm.weight', 'decoder.block.8.layer.0.SelfAttention.v.weight', 'decoder.block.13.layer.0.SelfAttention.o.weight', 'decoder.block.12.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.1.EncDecAttention.k.weight', 'decoder.block.14.layer.0.SelfAttention.k.weight', 'decoder.block.13.layer.0.SelfAttention.v.weight', 'decoder.block.7.layer.1.EncDecAttention.q.weight', 'decoder.block.17.layer.2.DenseReluDense.wo.weight', 'decoder.block.8.layer.1.EncDecAttention.o.weight', 'decoder.block.5.layer.0.layer_norm.weight', 'decoder.block.15.layer.1.EncDecAttention.k.weight', 'decoder.block.13.layer.1.EncDecAttention.k.weight', 'decoder.block.0.layer.2.DenseReluDense.wi.weight', 'decoder.block.21.layer.1.EncDecAttention.v.weight', 'decoder.block.20.layer.0.SelfAttention.v.weight', 'decoder.block.9.layer.2.DenseReluDense.wi.weight', 'decoder.block.13.layer.1.EncDecAttention.v.weight', 'decoder.block.9.layer.1.EncDecAttention.v.weight', 'decoder.block.10.layer.1.EncDecAttention.q.weight', 'decoder.block.6.layer.0.SelfAttention.q.weight', 'decoder.block.4.layer.1.EncDecAttention.q.weight', 'decoder.block.20.layer.2.layer_norm.weight', 'decoder.block.23.layer.1.EncDecAttention.v.weight', 'decoder.block.4.layer.2.layer_norm.weight', 'decoder.block.19.layer.2.DenseReluDense.wi.weight', 'decoder.block.0.layer.0.SelfAttention.k.weight', 'decoder.block.14.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.2.layer_norm.weight', 'decoder.block.15.layer.1.EncDecAttention.o.weight', 'decoder.block.9.layer.0.SelfAttention.v.weight', 'decoder.block.7.layer.0.SelfAttention.o.weight', 'decoder.block.22.layer.1.EncDecAttention.q.weight', 'decoder.block.23.layer.0.SelfAttention.v.weight', 'decoder.block.20.layer.1.EncDecAttention.q.weight', 'decoder.block.18.layer.1.layer_norm.weight', 'decoder.block.0.layer.1.EncDecAttention.v.weight', 'decoder.block.11.layer.0.layer_norm.weight', 'decoder.block.17.layer.1.EncDecAttention.k.weight', 'decoder.block.0.layer.2.DenseReluDense.wo.weight', 'decoder.block.3.layer.1.layer_norm.weight', 'decoder.block.15.layer.2.layer_norm.weight', 'decoder.block.9.layer.1.EncDecAttention.q.weight', 'decoder.block.20.layer.1.EncDecAttention.k.weight', 'decoder.block.5.layer.1.EncDecAttention.q.weight', 'decoder.block.12.layer.2.DenseReluDense.wo.weight', 'decoder.block.14.layer.0.SelfAttention.q.weight', 'decoder.block.15.layer.2.DenseReluDense.wi.weight', 'decoder.block.1.layer.2.layer_norm.weight', 'decoder.block.8.layer.1.EncDecAttention.q.weight', 'decoder.block.2.layer.0.SelfAttention.q.weight', 'decoder.block.23.layer.0.SelfAttention.o.weight', 'decoder.block.21.layer.1.EncDecAttention.q.weight', 'decoder.block.2.layer.0.SelfAttention.k.weight', 'decoder.block.0.layer.0.layer_norm.weight', 'decoder.block.21.layer.2.DenseReluDense.wi.weight', 'decoder.block.18.layer.1.EncDecAttention.o.weight', 'decoder.block.12.layer.1.EncDecAttention.v.weight', 'decoder.block.15.layer.1.EncDecAttention.q.weight', 'decoder.block.5.layer.2.DenseReluDense.wo.weight', 'decoder.block.9.layer.0.SelfAttention.o.weight', 'decoder.block.7.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.0.SelfAttention.q.weight', 'decoder.block.21.layer.0.SelfAttention.k.weight', 'decoder.block.16.layer.0.SelfAttention.v.weight', 'decoder.block.23.layer.0.layer_norm.weight', 'decoder.block.6.layer.1.EncDecAttention.o.weight', 'decoder.block.20.layer.1.EncDecAttention.v.weight', 'decoder.block.22.layer.0.SelfAttention.v.weight', 'decoder.block.10.layer.1.EncDecAttention.k.weight', 'decoder.block.1.layer.2.DenseReluDense.wo.weight', 'decoder.block.16.layer.0.layer_norm.weight', 'decoder.block.18.layer.2.DenseReluDense.wi.weight', 'decoder.block.16.layer.1.EncDecAttention.k.weight', 'decoder.block.10.layer.0.layer_norm.weight', 'decoder.block.15.layer.0.SelfAttention.k.weight', 'decoder.block.10.layer.1.EncDecAttention.o.weight', 'decoder.block.6.layer.0.SelfAttention.o.weight', 'decoder.block.12.layer.1.EncDecAttention.q.weight', 'decoder.block.4.layer.0.layer_norm.weight', 'decoder.block.16.layer.2.layer_norm.weight', 'decoder.block.18.layer.1.EncDecAttention.q.weight', 'decoder.block.22.layer.0.layer_norm.weight', 'decoder.block.3.layer.2.layer_norm.weight', 'decoder.block.20.layer.2.DenseReluDense.wo.weight', 'decoder.block.18.layer.0.layer_norm.weight', 'decoder.block.1.layer.0.SelfAttention.q.weight', 'decoder.block.3.layer.1.EncDecAttention.q.weight', 'decoder.block.19.layer.0.SelfAttention.v.weight', 'decoder.block.12.layer.0.SelfAttention.k.weight', 'decoder.block.0.layer.1.EncDecAttention.o.weight', 'decoder.block.15.layer.0.SelfAttention.o.weight', 'decoder.block.18.layer.0.SelfAttention.v.weight', 'decoder.block.3.layer.0.SelfAttention.v.weight', 'decoder.block.5.layer.1.EncDecAttention.k.weight', 'decoder.block.13.layer.2.DenseReluDense.wo.weight', 'decoder.block.8.layer.2.DenseReluDense.wi.weight', 'decoder.block.4.layer.0.SelfAttention.q.weight', 'decoder.block.17.layer.1.layer_norm.weight', 'decoder.block.22.layer.2.DenseReluDense.wo.weight', 'decoder.block.1.layer.1.EncDecAttention.q.weight', 'decoder.block.18.layer.2.layer_norm.weight', 'decoder.block.20.layer.0.SelfAttention.k.weight', 'decoder.block.22.layer.1.EncDecAttention.k.weight', 'decoder.block.2.layer.0.SelfAttention.v.weight', 'decoder.block.17.layer.2.DenseReluDense.wi.weight', 'decoder.block.20.layer.0.SelfAttention.q.weight', 'decoder.block.17.layer.0.layer_norm.weight', 'decoder.block.10.layer.1.EncDecAttention.v.weight', 'decoder.block.14.layer.0.layer_norm.weight', 'decoder.block.7.layer.1.EncDecAttention.v.weight', 'decoder.block.12.layer.2.layer_norm.weight', 'decoder.block.16.layer.1.EncDecAttention.q.weight', 'decoder.block.7.layer.1.EncDecAttention.k.weight', 'decoder.block.13.layer.0.SelfAttention.k.weight', 'decoder.block.1.layer.0.SelfAttention.v.weight', 'decoder.block.22.layer.0.SelfAttention.o.weight', 'decoder.block.1.layer.1.EncDecAttention.v.weight', 'decoder.block.8.layer.0.SelfAttention.k.weight', 'decoder.block.1.layer.1.EncDecAttention.o.weight', 'decoder.block.7.layer.0.layer_norm.weight', 'decoder.block.2.layer.1.EncDecAttention.o.weight', 'decoder.block.1.layer.1.EncDecAttention.k.weight', 'decoder.block.10.layer.2.DenseReluDense.wo.weight', 'decoder.block.16.layer.1.layer_norm.weight', 'decoder.block.18.layer.0.SelfAttention.q.weight', 'decoder.block.19.layer.1.EncDecAttention.v.weight', 'decoder.block.9.layer.1.EncDecAttention.k.weight', 'decoder.block.21.layer.1.layer_norm.weight', 'decoder.block.23.layer.2.layer_norm.weight', 'decoder.block.4.layer.0.SelfAttention.v.weight', 'decoder.block.8.layer.2.DenseReluDense.wo.weight', 'decoder.block.6.layer.2.DenseReluDense.wo.weight', 'decoder.block.13.layer.2.DenseReluDense.wi.weight', 'decoder.block.10.layer.0.SelfAttention.q.weight', 'decoder.block.5.layer.0.SelfAttention.o.weight', 'decoder.block.7.layer.2.DenseReluDense.wo.weight', 'decoder.block.11.layer.0.SelfAttention.v.weight', 'decoder.block.21.layer.0.layer_norm.weight', 'decoder.block.14.layer.1.EncDecAttention.q.weight', 'decoder.block.12.layer.2.DenseReluDense.wi.weight', 'decoder.block.16.layer.0.SelfAttention.q.weight', 'decoder.block.11.layer.1.EncDecAttention.q.weight', 'decoder.block.8.layer.0.layer_norm.weight', 'decoder.block.11.layer.2.DenseReluDense.wi.weight', 'decoder.block.19.layer.1.layer_norm.weight', 'decoder.block.19.layer.2.DenseReluDense.wo.weight', 'decoder.block.20.layer.0.SelfAttention.o.weight', 'decoder.block.10.layer.2.layer_norm.weight', 'decoder.block.14.layer.2.layer_norm.weight', 'decoder.block.5.layer.1.EncDecAttention.o.weight', 'decoder.block.10.layer.2.DenseReluDense.wi.weight', 'decoder.block.13.layer.1.layer_norm.weight', 'decoder.block.14.layer.2.DenseReluDense.wo.weight', 'decoder.block.9.layer.0.SelfAttention.k.weight', 'decoder.block.3.layer.0.SelfAttention.q.weight', 'decoder.block.3.layer.0.layer_norm.weight', 'decoder.block.1.layer.1.layer_norm.weight', 'decoder.final_layer_norm.weight', 'decoder.block.22.layer.2.layer_norm.weight', 'decoder.block.1.layer.0.SelfAttention.k.weight', 'decoder.block.18.layer.2.DenseReluDense.wo.weight', 'decoder.block.22.layer.1.layer_norm.weight', 'decoder.block.14.layer.1.EncDecAttention.k.weight', 'decoder.block.2.layer.1.EncDecAttention.k.weight', 'decoder.block.0.layer.0.SelfAttention.o.weight', 'decoder.block.3.layer.1.EncDecAttention.v.weight', 'decoder.block.7.layer.1.EncDecAttention.o.weight', 'decoder.block.14.layer.2.DenseReluDense.wi.weight', 'decoder.block.19.layer.0.SelfAttention.k.weight', 'decoder.block.5.layer.0.SelfAttention.q.weight', 'decoder.block.1.layer.0.layer_norm.weight', 'decoder.block.22.layer.1.EncDecAttention.v.weight', 'decoder.block.9.layer.1.EncDecAttention.o.weight', 'decoder.block.7.layer.2.DenseReluDense.wi.weight', 'decoder.block.20.layer.1.layer_norm.weight', 'decoder.block.12.layer.0.SelfAttention.q.weight', 'decoder.block.12.layer.0.SelfAttention.o.weight', 'decoder.block.16.layer.2.DenseReluDense.wi.weight', 'decoder.block.12.layer.1.EncDecAttention.o.weight', 'decoder.block.4.layer.1.EncDecAttention.o.weight', 'decoder.block.5.layer.1.EncDecAttention.v.weight', 'decoder.block.13.layer.1.EncDecAttention.q.weight', 'decoder.block.2.layer.2.layer_norm.weight', 'decoder.block.20.layer.2.DenseReluDense.wi.weight', 'decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'decoder.block.16.layer.1.EncDecAttention.o.weight', 'decoder.block.17.layer.0.SelfAttention.v.weight', 'decoder.block.20.layer.1.EncDecAttention.o.weight', 'decoder.block.6.layer.1.layer_norm.weight', 'decoder.block.10.layer.0.SelfAttention.k.weight', 'decoder.block.17.layer.1.EncDecAttention.q.weight', 'decoder.block.17.layer.0.SelfAttention.q.weight', 'decoder.block.22.layer.2.DenseReluDense.wi.weight', 'decoder.block.20.layer.0.layer_norm.weight', 'decoder.block.19.layer.0.SelfAttention.o.weight', 'decoder.block.8.layer.0.SelfAttention.o.weight', 'decoder.block.23.layer.2.DenseReluDense.wi.weight', 'decoder.block.4.layer.0.SelfAttention.o.weight', 'decoder.block.11.layer.1.EncDecAttention.v.weight', 'decoder.block.4.layer.1.EncDecAttention.v.weight', 'decoder.block.23.layer.0.SelfAttention.q.weight', 'decoder.block.4.layer.1.EncDecAttention.k.weight', 'decoder.block.18.layer.0.SelfAttention.k.weight', 'decoder.block.21.layer.1.EncDecAttention.o.weight', 'decoder.block.13.layer.1.EncDecAttention.o.weight', 'decoder.block.17.layer.2.layer_norm.weight', 'decoder.block.14.layer.1.layer_norm.weight', 'decoder.block.19.layer.1.EncDecAttention.q.weight', 'decoder.block.5.layer.2.DenseReluDense.wi.weight', 'decoder.block.21.layer.0.SelfAttention.o.weight', 'decoder.block.2.layer.1.layer_norm.weight', 'decoder.block.15.layer.0.SelfAttention.v.weight', 'decoder.block.11.layer.1.EncDecAttention.k.weight', 'decoder.block.7.layer.0.SelfAttention.k.weight', 'decoder.block.16.layer.0.SelfAttention.k.weight', 'decoder.block.14.layer.0.SelfAttention.o.weight', 'decoder.block.15.layer.2.DenseReluDense.wo.weight', 'decoder.block.5.layer.2.layer_norm.weight', 'decoder.block.6.layer.2.DenseReluDense.wi.weight', 'decoder.block.19.layer.2.layer_norm.weight', 'decoder.block.6.layer.0.SelfAttention.v.weight', 'decoder.block.11.layer.1.EncDecAttention.o.weight', 'decoder.block.19.layer.0.SelfAttention.q.weight', 'decoder.block.11.layer.2.DenseReluDense.wo.weight', 'decoder.block.1.layer.2.DenseReluDense.wi.weight', 'decoder.block.10.layer.0.SelfAttention.o.weight', 'decoder.block.11.layer.0.SelfAttention.q.weight', 'decoder.block.2.layer.2.DenseReluDense.wo.weight', 'decoder.block.6.layer.0.SelfAttention.k.weight', 'decoder.block.8.layer.0.SelfAttention.q.weight', 'decoder.block.17.layer.0.SelfAttention.o.weight', 'decoder.block.11.layer.1.layer_norm.weight', 'decoder.block.9.layer.0.SelfAttention.q.weight', 'decoder.block.2.layer.0.layer_norm.weight', 'decoder.block.2.layer.1.EncDecAttention.v.weight', 'decoder.block.2.layer.1.EncDecAttention.q.weight', 'decoder.block.12.layer.1.layer_norm.weight', 'decoder.block.3.layer.0.SelfAttention.k.weight', 'decoder.block.21.layer.1.EncDecAttention.k.weight', 'decoder.block.7.layer.1.layer_norm.weight', 'decoder.block.5.layer.0.SelfAttention.v.weight', 'decoder.block.6.layer.1.EncDecAttention.v.weight', 'decoder.block.0.layer.1.layer_norm.weight', 'decoder.block.14.layer.1.EncDecAttention.v.weight', 'decoder.block.0.layer.0.SelfAttention.v.weight', 'decoder.block.2.layer.0.SelfAttention.o.weight', 'decoder.block.18.layer.1.EncDecAttention.v.weight', 'decoder.block.11.layer.0.SelfAttention.o.weight', 'decoder.block.6.layer.0.layer_norm.weight', 'decoder.block.10.layer.1.layer_norm.weight', 'decoder.block.0.layer.1.EncDecAttention.q.weight', 'decoder.block.8.layer.1.layer_norm.weight', 'decoder.block.15.layer.1.EncDecAttention.v.weight', 'decoder.block.23.layer.1.EncDecAttention.o.weight', 'decoder.block.10.layer.0.SelfAttention.v.weight', 'decoder.block.13.layer.0.layer_norm.weight', 'decoder.block.11.layer.2.layer_norm.weight', 'decoder.block.15.layer.0.SelfAttention.q.weight', 'decoder.block.19.layer.1.EncDecAttention.k.weight', 'decoder.block.7.layer.2.layer_norm.weight', 'decoder.block.15.layer.0.layer_norm.weight', 'decoder.block.17.layer.0.SelfAttention.k.weight', 'decoder.block.21.layer.2.layer_norm.weight', 'decoder.block.6.layer.1.EncDecAttention.k.weight', 'decoder.block.9.layer.2.layer_norm.weight', 'decoder.block.18.layer.1.EncDecAttention.k.weight', 'decoder.block.3.layer.1.EncDecAttention.k.weight', 'decoder.block.1.layer.0.SelfAttention.o.weight', 'decoder.block.8.layer.1.EncDecAttention.k.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "bert_model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "\"\"\"\n",
    "\n",
    "model = AutoModel.from_pretrained(\"hkunlp/instructor-xl\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"hkunlp/instructor-xl\")\n",
    "\n",
    "instructor_model = INSTRUCTOR('hkunlp/instructor-xl')\n",
    "\n",
    "def sentence_embedder(sentence):\n",
    "    \"\"\"\n",
    "    desc_tokenized = bert_tokenizer(sentence, return_tensors=\"pt\", max_length=512, truncation=True, padding='max_length')\n",
    "    outputs = bert_model(**desc_tokenized)\n",
    "    emb = outputs.to_tuple()[0][0][0].detach().numpy().tolist()\n",
    "\n",
    "    instruction = \"Represent the medical report: \"\n",
    "    emb = instructor_model.encode([[instruction,sentence]])[0]\n",
    "    \"\"\"\n",
    "    desc_tokenized = tokenizer(sentence, return_tensors=\"pt\", max_length=512, truncation=True, padding='max_length')\n",
    "    outputs = model.encoder(**desc_tokenized)\n",
    "    emb = outputs.to_tuple()[0][0][0].detach().numpy().tolist()\n",
    "\n",
    "    \n",
    "    return emb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.004771108273416758,\n",
       " 2.7125438464281615e-06,\n",
       " 0.0005939982365816832,\n",
       " 0.007692752871662378,\n",
       " -0.015331124886870384,\n",
       " -0.005043820012360811,\n",
       " -0.00029530952451750636,\n",
       " 0.008700672537088394,\n",
       " 0.00036012058262713253,\n",
       " -0.006412765942513943,\n",
       " -0.000656678865198046,\n",
       " 0.00020917189249303192,\n",
       " -0.0007234543445520103,\n",
       " 0.013471362181007862,\n",
       " 0.0072924974374473095,\n",
       " -0.0003818754921667278,\n",
       " -0.006200540345162153,\n",
       " 0.0009474895778112113,\n",
       " -0.01113874651491642,\n",
       " 0.0013307032641023397,\n",
       " 0.008734891191124916,\n",
       " -0.010341615416109562,\n",
       " -0.0005118698463775218,\n",
       " -0.006783982738852501,\n",
       " -0.0061095161363482475,\n",
       " 0.0032137094531208277,\n",
       " -0.007403821684420109,\n",
       " -0.00010674659279175103,\n",
       " 0.0015858800616115332,\n",
       " -0.009795425459742546,\n",
       " 0.002453387947753072,\n",
       " -0.0030628317035734653,\n",
       " 0.015612823888659477,\n",
       " -0.0009050660883076489,\n",
       " -0.0010058542247861624,\n",
       " 0.01755446195602417,\n",
       " 0.008880335837602615,\n",
       " 0.005693390499800444,\n",
       " 0.001905712764710188,\n",
       " -0.0021939801517874002,\n",
       " -0.002515119267627597,\n",
       " -0.002176211681216955,\n",
       " 0.004870325326919556,\n",
       " -0.022937780246138573,\n",
       " 0.0072706639766693115,\n",
       " -0.006602403242141008,\n",
       " -0.007441280875355005,\n",
       " -0.0016186652937904,\n",
       " -0.0005392396706156433,\n",
       " 0.0018802479607984424,\n",
       " 0.004333499353379011,\n",
       " -0.0003641546063590795,\n",
       " -0.0032856047619134188,\n",
       " -0.004714176990091801,\n",
       " 0.005842036567628384,\n",
       " -0.009400015696883202,\n",
       " 0.00037588627310469747,\n",
       " -0.008624451234936714,\n",
       " 0.002874829573556781,\n",
       " 0.006777874659746885,\n",
       " 0.004887016490101814,\n",
       " 0.011209482327103615,\n",
       " 0.004797809291630983,\n",
       " -0.00351146562024951,\n",
       " -0.0035703028552234173,\n",
       " 0.007214278914034367,\n",
       " -0.003391234902665019,\n",
       " -0.0031432881951332092,\n",
       " 0.009301641024649143,\n",
       " 0.0007456007297150791,\n",
       " 0.001513972645625472,\n",
       " -0.005511733237653971,\n",
       " 0.0019203798146918416,\n",
       " -0.0068110316060483456,\n",
       " -0.0025658183731138706,\n",
       " -0.013267822563648224,\n",
       " -0.0016274695517495275,\n",
       " -0.005283305887132883,\n",
       " 0.002071667229756713,\n",
       " -0.0066374437883496284,\n",
       " -0.0009911457309499383,\n",
       " 0.005731481593102217,\n",
       " -0.000874576682690531,\n",
       " 0.00026582402642816305,\n",
       " 0.007394321728497744,\n",
       " 0.006296014878898859,\n",
       " -0.010213829576969147,\n",
       " -0.00028425094205886126,\n",
       " -0.0027906610630452633,\n",
       " 0.006143803708255291,\n",
       " 0.004439854994416237,\n",
       " -0.00839237030595541,\n",
       " 0.0050573875196278095,\n",
       " -0.000556127808522433,\n",
       " -0.012978498823940754,\n",
       " 0.004148879554122686,\n",
       " -0.004769094288349152,\n",
       " 0.019289299845695496,\n",
       " 0.014957907609641552,\n",
       " -0.010835179127752781,\n",
       " 0.00536957336589694,\n",
       " -0.017970629036426544,\n",
       " 0.002807057462632656,\n",
       " -0.0010404989589005709,\n",
       " -0.012309767305850983,\n",
       " 0.007158465217798948,\n",
       " 0.004640465602278709,\n",
       " -0.0052949851378798485,\n",
       " 0.04910709708929062,\n",
       " 0.0029506904538720846,\n",
       " -0.015613476745784283,\n",
       " 0.004802171140909195,\n",
       " -0.0002584410540293902,\n",
       " -0.005239224061369896,\n",
       " -0.004984733648598194,\n",
       " 0.0056958575733006,\n",
       " -0.004046101588755846,\n",
       " 0.00689267972484231,\n",
       " 0.010737539269030094,\n",
       " 0.0034130823332816362,\n",
       " 0.0039711641147732735,\n",
       " -0.010184083133935928,\n",
       " 0.0008022685651667416,\n",
       " 0.014136744663119316,\n",
       " 0.005000443663448095,\n",
       " -0.0027443331200629473,\n",
       " -0.0043310620822012424,\n",
       " -0.0025864834897220135,\n",
       " 0.010084262117743492,\n",
       " -0.005243373103439808,\n",
       " -0.0020879239309579134,\n",
       " -0.003535010851919651,\n",
       " -0.016023850068449974,\n",
       " -0.012279393151402473,\n",
       " -0.006303304340690374,\n",
       " 0.002092708135023713,\n",
       " -0.00424899160861969,\n",
       " 0.00848445575684309,\n",
       " 0.000333014118950814,\n",
       " 0.012037823908030987,\n",
       " -0.004597678780555725,\n",
       " -0.005600131582468748,\n",
       " 0.010601470246911049,\n",
       " -0.0024206587113440037,\n",
       " -0.016534904018044472,\n",
       " 0.006611734163016081,\n",
       " 0.0038727910723537207,\n",
       " -0.007637187372893095,\n",
       " -0.0043686009012162685,\n",
       " -0.004401186015456915,\n",
       " -0.005300568416714668,\n",
       " 0.008298435248434544,\n",
       " 0.0038465543184429407,\n",
       " 0.0008260991889983416,\n",
       " -0.0021084127947688103,\n",
       " -0.007382932584732771,\n",
       " 0.005474831443279982,\n",
       " -0.0004461118078324944,\n",
       " 0.006493973080068827,\n",
       " -0.004983379505574703,\n",
       " 0.006591183599084616,\n",
       " 0.002824879717081785,\n",
       " -0.002285420661792159,\n",
       " 0.0010632304474711418,\n",
       " -0.016357528045773506,\n",
       " -0.00040001276647672057,\n",
       " -0.002190403873100877,\n",
       " 0.0001726733025861904,\n",
       " -0.0028921461198478937,\n",
       " -0.009772962890565395,\n",
       " -0.0024431420024484396,\n",
       " -0.009622468613088131,\n",
       " 0.002920403378084302,\n",
       " -0.008371195755898952,\n",
       " -0.00011009092122549191,\n",
       " 0.0012882709270343184,\n",
       " 0.007168083917349577,\n",
       " -0.0031415438279509544,\n",
       " -0.0003443562309257686,\n",
       " -0.002594608813524246,\n",
       " 0.0011692524421960115,\n",
       " 0.01204878743737936,\n",
       " -0.01396659854799509,\n",
       " 0.0053972601890563965,\n",
       " -0.011779101565480232,\n",
       " 0.005377438385039568,\n",
       " -0.0030530299991369247,\n",
       " -0.0024565511848777533,\n",
       " 0.012932196259498596,\n",
       " -0.005152858328074217,\n",
       " -0.0062356689013540745,\n",
       " -0.007068172562867403,\n",
       " 0.008685492910444736,\n",
       " 0.002014533383771777,\n",
       " -0.04369691386818886,\n",
       " -0.002604232868179679,\n",
       " -0.013074289076030254,\n",
       " 0.0012009723577648401,\n",
       " -0.008653306402266026,\n",
       " -0.008022227324545383,\n",
       " 0.016724731773138046,\n",
       " 0.00250190868973732,\n",
       " 0.010849734768271446,\n",
       " -0.008440294302999973,\n",
       " 0.004731097258627415,\n",
       " -0.003763860324397683,\n",
       " 0.005223546177148819,\n",
       " -0.002569068456068635,\n",
       " 0.003580548334866762,\n",
       " 0.01550271362066269,\n",
       " 0.00903861690312624,\n",
       " 0.0016593197360634804,\n",
       " -0.003882030723616481,\n",
       " -0.0001824400678742677,\n",
       " 0.0036134885158389807,\n",
       " 0.007564065977931023,\n",
       " 0.0013565014814957976,\n",
       " 0.0051193381659686565,\n",
       " 1.625979712116532e-05,\n",
       " 0.01182734128087759,\n",
       " -0.005389282014220953,\n",
       " -0.01409726683050394,\n",
       " -0.004383256658911705,\n",
       " 2.5545288735884242e-05,\n",
       " -0.004802956711500883,\n",
       " 0.0048277839086949825,\n",
       " -0.000725592311937362,\n",
       " 0.00531900767236948,\n",
       " 0.0005160483997315168,\n",
       " -0.012876258231699467,\n",
       " -0.01152108982205391,\n",
       " 0.008817453868687153,\n",
       " 0.0008387645939365029,\n",
       " -0.0019460410112515092,\n",
       " 0.002543260809034109,\n",
       " 0.0030834763310849667,\n",
       " -0.006828293204307556,\n",
       " -0.0014722594060003757,\n",
       " 0.0030346785206347704,\n",
       " -0.004606818314641714,\n",
       " 0.00015364671708084643,\n",
       " 0.0006604402442462742,\n",
       " 0.0021603479981422424,\n",
       " 0.008122921921312809,\n",
       " -0.006161987781524658,\n",
       " -0.007989630103111267,\n",
       " 0.0009575925651006401,\n",
       " -0.0071703409776091576,\n",
       " 0.004665335174649954,\n",
       " -0.003611321095377207,\n",
       " -3.417789048398845e-05,\n",
       " -0.0015997107839211822,\n",
       " 0.0024538158904761076,\n",
       " 0.0010006577940657735,\n",
       " 0.001780135091394186,\n",
       " -0.0003085439093410969,\n",
       " -0.000778897141572088,\n",
       " 0.012581409886479378,\n",
       " 0.004124628845602274,\n",
       " -0.005648109130561352,\n",
       " 0.002788861282169819,\n",
       " -0.01610700599849224,\n",
       " -0.00896380003541708,\n",
       " -0.013901236467063427,\n",
       " 0.012910913676023483,\n",
       " 0.0062246681191027164,\n",
       " 0.008508073166012764,\n",
       " 0.0035380390472710133,\n",
       " -0.010864674113690853,\n",
       " -0.005327585618942976,\n",
       " -0.00635886937379837,\n",
       " 0.013607073575258255,\n",
       " 0.0017482597613707185,\n",
       " 0.012033063918352127,\n",
       " 0.003172315424308181,\n",
       " 0.007163123693317175,\n",
       " -0.0007048093830235302,\n",
       " 0.007497054990381002,\n",
       " -0.00033385574351996183,\n",
       " 0.007093657739460468,\n",
       " -0.010199337266385555,\n",
       " -0.005337808281183243,\n",
       " 0.003833906026557088,\n",
       " -0.005869921296834946,\n",
       " -0.07551257312297821,\n",
       " 0.0038192218635231256,\n",
       " 0.011219616048038006,\n",
       " -0.0001840141339926049,\n",
       " 0.015154887922108173,\n",
       " -0.003983593545854092,\n",
       " 0.004192238673567772,\n",
       " -0.007036977913230658,\n",
       " -0.0074467784725129604,\n",
       " 0.010524840094149113,\n",
       " 0.0033425118308514357,\n",
       " 0.0012195659801363945,\n",
       " 0.002703736536204815,\n",
       " 0.006306080613285303,\n",
       " 0.0020958050154149532,\n",
       " -0.006867155898362398,\n",
       " -0.009473132900893688,\n",
       " -0.008964347653090954,\n",
       " -0.0021667720284312963,\n",
       " 0.0036841435357928276,\n",
       " -0.0010389917297288775,\n",
       " 0.003818094963207841,\n",
       " 0.005356005392968655,\n",
       " 0.013403020799160004,\n",
       " 0.006418249569833279,\n",
       " 0.0050691282376646996,\n",
       " -0.061189569532871246,\n",
       " 0.011469267308712006,\n",
       " 0.006274698302149773,\n",
       " 0.002226331504061818,\n",
       " 0.0038149061147123575,\n",
       " -0.005175736732780933,\n",
       " 0.0068491254933178425,\n",
       " 0.007761940825730562,\n",
       " -0.001148581737652421,\n",
       " -0.01806361973285675,\n",
       " -0.003646855941042304,\n",
       " 0.004206428304314613,\n",
       " -0.001223735511302948,\n",
       " -0.005961528047919273,\n",
       " -0.0023396522738039494,\n",
       " 0.012923221103847027,\n",
       " 0.0009507989161647856,\n",
       " -0.0067194984294474125,\n",
       " -0.0036179206799715757,\n",
       " 0.009318923577666283,\n",
       " -0.004723528400063515,\n",
       " 0.012459071353077888,\n",
       " -0.015835929661989212,\n",
       " 0.008218243718147278,\n",
       " -0.006332617253065109,\n",
       " -0.003844961291179061,\n",
       " 0.004245896358042955,\n",
       " 0.006813779007643461,\n",
       " -0.003146439092233777,\n",
       " -0.0033827966544777155,\n",
       " 0.008433235809206963,\n",
       " 0.012408093549311161,\n",
       " 0.0082270922139287,\n",
       " 0.00041373216663487256,\n",
       " 0.005144069902598858,\n",
       " 0.010470547713339329,\n",
       " -0.005118263885378838,\n",
       " 0.010614483617246151,\n",
       " -0.0061653670854866505,\n",
       " -0.0040703704580664635,\n",
       " 0.0015552520053461194,\n",
       " 0.0034658261574804783,\n",
       " -0.0066330828703939915,\n",
       " 0.0019640065729618073,\n",
       " -0.006733797490596771,\n",
       " 0.003862411016598344,\n",
       " 0.008887515403330326,\n",
       " -0.014937372878193855,\n",
       " 0.003963477909564972,\n",
       " 0.005577836185693741,\n",
       " 0.004767853766679764,\n",
       " 0.01392855029553175,\n",
       " -0.006906847003847361,\n",
       " -0.0015415342058986425,\n",
       " 0.0077159409411251545,\n",
       " -0.0016264552250504494,\n",
       " -0.006443149410188198,\n",
       " 0.006585407070815563,\n",
       " -0.007235840894281864,\n",
       " -0.0018581508193165064,\n",
       " 0.004561358131468296,\n",
       " -0.004267543088644743,\n",
       " 0.009091157466173172,\n",
       " 4.392336632008664e-05,\n",
       " 0.005425061099231243,\n",
       " 0.004801651928573847,\n",
       " -0.004094766918569803,\n",
       " -0.007020739372819662,\n",
       " -0.008745723403990269,\n",
       " 0.007634409237653017,\n",
       " -0.002772966166958213,\n",
       " -0.005749658681452274,\n",
       " 0.0030239459592849016,\n",
       " 0.002128101419657469,\n",
       " 0.017796866595745087,\n",
       " 0.002111230744048953,\n",
       " 0.006403681822121143,\n",
       " 0.002930690301582217,\n",
       " 0.001064975163899362,\n",
       " -0.0015743226977065206,\n",
       " 0.008408350870013237,\n",
       " -0.006386704742908478,\n",
       " -0.0005099596455693245,\n",
       " 0.0065882024355232716,\n",
       " 0.01307707093656063,\n",
       " 0.0018983882619068027,\n",
       " -0.0054182386957108974,\n",
       " -0.0015302186366170645,\n",
       " 0.005164917092770338,\n",
       " 0.008985302411019802,\n",
       " 0.006414179224520922,\n",
       " -0.0005295960581861436,\n",
       " -0.013333451934158802,\n",
       " 0.0023300559259951115,\n",
       " 0.0031751522328704596,\n",
       " 0.01563970185816288,\n",
       " -0.0039003321435302496,\n",
       " 0.0031891230028122663,\n",
       " 0.001430750242434442,\n",
       " -0.002199349692091346,\n",
       " -0.007647077552974224,\n",
       " -0.004145316779613495,\n",
       " 0.0012852402869611979,\n",
       " 0.006390929687768221,\n",
       " -0.003569547086954117,\n",
       " 0.004135566297918558,\n",
       " 0.002968378597870469,\n",
       " -0.0008269270183518529,\n",
       " -0.001822367892600596,\n",
       " -0.0035350194666534662,\n",
       " -0.00883250217884779,\n",
       " -0.005272678565233946,\n",
       " 0.0026508322916924953,\n",
       " -0.0054230233654379845,\n",
       " -0.0016973612364381552,\n",
       " 0.0016346578486263752,\n",
       " 0.07805583626031876,\n",
       " 0.0042213681153953075,\n",
       " -0.0029994428623467684,\n",
       " 0.0033395623322576284,\n",
       " -0.01592281274497509,\n",
       " 0.009985161945223808,\n",
       " 0.007116568274796009,\n",
       " 0.00513335270807147,\n",
       " -0.008569831028580666,\n",
       " 0.00031051100813783705,\n",
       " 0.011535285040736198,\n",
       " -0.006743568927049637,\n",
       " -0.010475607588887215,\n",
       " 0.009342326782643795,\n",
       " 0.0009009128552861512,\n",
       " 0.007171063683927059,\n",
       " 0.0033771551679819822,\n",
       " -0.010213576257228851,\n",
       " 0.002431232249364257,\n",
       " -0.0012651660945266485,\n",
       " 0.011082257144153118,\n",
       " -0.0013635284267365932,\n",
       " 0.002173095243051648,\n",
       " 0.0029640854336321354,\n",
       " -0.001566717168316245,\n",
       " 0.013773689046502113,\n",
       " -0.007796422578394413,\n",
       " -0.0022604260593652725,\n",
       " -0.013902537524700165,\n",
       " -0.008059806190431118,\n",
       " -0.0008809661958366632,\n",
       " -0.01031150296330452,\n",
       " 0.0017386899562552571,\n",
       " 0.0015941328601911664,\n",
       " 0.0036017117090523243,\n",
       " 0.0011103191645815969,\n",
       " -0.0017134881345555186,\n",
       " 0.0076625291258096695,\n",
       " 0.002305184258148074,\n",
       " 0.001803633407689631,\n",
       " -0.002588944509625435,\n",
       " -0.007994435727596283,\n",
       " 0.01149391382932663,\n",
       " 0.0028086688835173845,\n",
       " 0.005472766235470772,\n",
       " -0.011196340434253216,\n",
       " -0.011328320018947124,\n",
       " 0.005284443031996489,\n",
       " 0.0005206351634114981,\n",
       " 0.0011017656652256846,\n",
       " -0.01256018877029419,\n",
       " -0.006452072411775589,\n",
       " -0.0022732994984835386,\n",
       " 0.005042698234319687,\n",
       " -0.005457925144582987,\n",
       " -0.00026839811471290886,\n",
       " -0.002843304071575403,\n",
       " -0.005468834191560745,\n",
       " -0.005245123524218798,\n",
       " -0.013078968040645123,\n",
       " 0.0047720130532979965,\n",
       " -0.011077509261667728,\n",
       " -0.0051723625510931015,\n",
       " 0.0018336826469749212,\n",
       " 0.006344852037727833,\n",
       " 0.0027378343511372805,\n",
       " 0.004034801386296749,\n",
       " 0.0059079392813146114,\n",
       " 0.015561931766569614,\n",
       " -0.005150632467120886,\n",
       " 0.0018438154365867376,\n",
       " -0.007863896898925304,\n",
       " 0.004732170607894659,\n",
       " -0.0003493384865578264,\n",
       " -0.0025526511017233133,\n",
       " 0.0016870994586497545,\n",
       " 0.008789599873125553,\n",
       " -0.08860956132411957,\n",
       " 0.000872126140166074,\n",
       " -0.003909721039235592,\n",
       " -0.007903731428086758,\n",
       " -0.005743012297898531,\n",
       " -0.005574898328632116,\n",
       " -0.006894739344716072,\n",
       " -0.0030330910813063383,\n",
       " 0.0012419874547049403,\n",
       " -0.0022809661459177732,\n",
       " 0.005868338979780674,\n",
       " -0.0044633797369897366,\n",
       " -0.0055936239659786224,\n",
       " 0.009737616404891014,\n",
       " 0.009202645160257816,\n",
       " -0.003916154149919748,\n",
       " 0.009259521961212158,\n",
       " 0.0009054212714545429,\n",
       " -0.003291458822786808,\n",
       " -0.0031906990334391594,\n",
       " 0.0002579621796030551,\n",
       " 0.002561545465141535,\n",
       " 0.008227772079408169,\n",
       " -0.0045860237441957,\n",
       " -0.009987137280404568,\n",
       " 0.0011965809389948845,\n",
       " -0.00782159622758627,\n",
       " -0.0020864391699433327,\n",
       " -0.0026807195972651243,\n",
       " 0.0022724145092070103,\n",
       " 0.012738317251205444,\n",
       " -0.009789370000362396,\n",
       " -0.006328394636511803,\n",
       " 0.00319344038143754,\n",
       " 0.005718640983104706,\n",
       " 0.01187503058463335,\n",
       " 0.003073315601795912,\n",
       " -0.0020029316656291485,\n",
       " 0.011330914683640003,\n",
       " 0.0020823096856474876,\n",
       " 0.0015763809205964208,\n",
       " 0.0045426394790410995,\n",
       " -0.011850578710436821,\n",
       " -0.0019508949480950832,\n",
       " -0.00787200964987278,\n",
       " -0.0016740096034482121,\n",
       " 0.004172022920101881,\n",
       " 0.005664675962179899,\n",
       " 0.0033321345690637827,\n",
       " -0.006055627949535847,\n",
       " -0.011695679277181625,\n",
       " -0.00834844633936882,\n",
       " 0.0007687799516133964,\n",
       " -0.006038163788616657,\n",
       " -0.008359121158719063,\n",
       " 0.0015416219830513,\n",
       " 0.006335701327770948,\n",
       " -0.010845180600881577,\n",
       " -0.0033126152120530605,\n",
       " -0.006693755276501179,\n",
       " 0.0075907716527581215,\n",
       " 0.00513313477858901,\n",
       " -0.0038645509630441666,\n",
       " 0.008378880098462105,\n",
       " 0.004569385666400194,\n",
       " -0.0028930935077369213,\n",
       " 0.00958134513348341,\n",
       " 0.0009567521046847105,\n",
       " 0.005048626102507114,\n",
       " 0.010218997485935688,\n",
       " 0.007638491690158844,\n",
       " 0.006900649983435869,\n",
       " 0.0007126269047148526,\n",
       " 0.0007419256144203246,\n",
       " -0.02372051402926445,\n",
       " 0.014803645201027393,\n",
       " 0.002571031218394637,\n",
       " 4.65885859739501e-05,\n",
       " -0.006354236043989658,\n",
       " -0.0018643031362444162,\n",
       " -0.00753202335909009,\n",
       " -0.01189020648598671,\n",
       " 0.004339430946856737,\n",
       " -0.0002475441724527627,\n",
       " -0.003012037603184581,\n",
       " 0.004267401061952114,\n",
       " -0.0019617436919361353,\n",
       " -0.005200443789362907,\n",
       " -0.0010699477279558778,\n",
       " -0.0043355138041079044,\n",
       " 0.0028366106562316418,\n",
       " 0.00028235430363565683,\n",
       " -0.005480377934873104,\n",
       " 0.0017290427349507809,\n",
       " 0.00014439219376072288,\n",
       " 0.009175043553113937,\n",
       " -0.014654438011348248,\n",
       " 0.007683480624109507,\n",
       " 0.0010550854494795203,\n",
       " 0.008785376325249672,\n",
       " 0.0038274768739938736,\n",
       " -0.0038365176878869534,\n",
       " 0.012631562538444996,\n",
       " 0.0020327784586697817,\n",
       " -0.0023610403295606375,\n",
       " 0.0022647944279015064,\n",
       " -0.00659366138279438,\n",
       " -0.0010831484105437994,\n",
       " -0.00011912119953194633,\n",
       " -0.0001459749328205362,\n",
       " 0.0027842014096677303,\n",
       " 0.009758354164659977,\n",
       " 0.006402058061212301,\n",
       " 0.001515040174126625,\n",
       " 0.0020734257996082306,\n",
       " 0.0024938490241765976,\n",
       " 0.004699308425188065,\n",
       " -0.007875542156398296,\n",
       " 0.0026608919724822044,\n",
       " -0.005320732016116381,\n",
       " -0.000265013484749943,\n",
       " 0.006957597564905882,\n",
       " -0.002594901481643319,\n",
       " -0.000661129888612777,\n",
       " 0.0009218351915478706,\n",
       " 0.002263071481138468,\n",
       " 0.015133341774344444,\n",
       " 0.009339691139757633,\n",
       " -0.013728169724345207,\n",
       " 0.0022380466107279062,\n",
       " -0.001422413857653737,\n",
       " 0.007007474545389414,\n",
       " 0.007005831226706505,\n",
       " 0.0017689880914986134,\n",
       " 0.0020352336578071117,\n",
       " 0.008294088765978813,\n",
       " 0.005761739332228899,\n",
       " 0.005151423159986734,\n",
       " 0.008479894138872623,\n",
       " 0.05462684854865074,\n",
       " 0.010556482709944248,\n",
       " -0.0011800160864368081,\n",
       " -0.007268709130585194,\n",
       " -0.007770438678562641,\n",
       " -0.006574118509888649,\n",
       " 0.0013732132501900196,\n",
       " 0.005552361719310284,\n",
       " -0.001285644480958581,\n",
       " 0.009979527443647385,\n",
       " 0.008726528845727444,\n",
       " 0.005309554282575846,\n",
       " 0.0041794548742473125,\n",
       " -0.007186374627053738,\n",
       " 0.009770005941390991,\n",
       " -0.004582225810736418,\n",
       " 0.010909989476203918,\n",
       " 0.014805170707404613,\n",
       " -0.011793040670454502,\n",
       " -0.009331347420811653,\n",
       " 0.0008062823326326907,\n",
       " -0.008353634737432003,\n",
       " 0.004550834186375141,\n",
       " -0.009456977248191833,\n",
       " 0.01760425977408886,\n",
       " 0.005031928885728121,\n",
       " -0.005013427697122097,\n",
       " 0.04143890365958214,\n",
       " 0.00334967952221632,\n",
       " 0.006983078084886074,\n",
       " -0.00016656883235555142,\n",
       " -0.00172622490208596,\n",
       " -0.01011230330914259,\n",
       " 0.011123837903141975,\n",
       " -0.011530919000506401,\n",
       " -0.0029295438434928656,\n",
       " -0.006735163740813732,\n",
       " 0.004678979981690645,\n",
       " 0.0005012718611396849,\n",
       " 0.003457216080278158,\n",
       " -0.011153750121593475,\n",
       " 0.010510374791920185,\n",
       " 0.0034170534927397966,\n",
       " -0.004353513475507498,\n",
       " -8.85415865923278e-05,\n",
       " 0.0006477104616351426,\n",
       " -0.010529952123761177,\n",
       " -0.003765840083360672,\n",
       " -0.0003767056914512068,\n",
       " 0.003995970822870731,\n",
       " -1.771423194441013e-05,\n",
       " -0.004132598172873259,\n",
       " -0.0006162659265100956,\n",
       " 0.0128555903211236,\n",
       " 0.012593341991305351,\n",
       " 0.022060226649045944,\n",
       " -0.005138127598911524,\n",
       " 0.007560995873063803,\n",
       " -0.006154385861009359,\n",
       " 0.0008457711664959788,\n",
       " 0.0072886161506175995,\n",
       " -0.004650393966585398,\n",
       " -0.00317907752469182,\n",
       " -0.003491619136184454,\n",
       " -0.0026772802229970694,\n",
       " -5.6840064644347876e-05,\n",
       " -0.009670572355389595,\n",
       " 0.00521677453070879,\n",
       " -0.016073284670710564,\n",
       " -0.0007270864443853498,\n",
       " -0.0069916583597660065,\n",
       " -0.0033725055400282145,\n",
       " 0.003271839115768671,\n",
       " -0.004143041558563709,\n",
       " -0.0052662985399365425,\n",
       " 0.007980470545589924,\n",
       " -0.008374977856874466,\n",
       " -0.004830833990126848,\n",
       " -0.07834803313016891,\n",
       " 0.007031184621155262,\n",
       " -0.0033768347930163145,\n",
       " 0.006386262364685535,\n",
       " -0.0023905045818537474,\n",
       " -0.009241080842912197,\n",
       " -0.009334013797342777,\n",
       " -0.0005128515185788274,\n",
       " 0.005191604606807232,\n",
       " -0.0075212204828858376,\n",
       " 0.0012385558802634478,\n",
       " -0.004463090095669031,\n",
       " -0.00499965064227581,\n",
       " 0.0010231632040813565,\n",
       " 0.0009725886047817767,\n",
       " -0.0009258163627237082,\n",
       " 0.007598873693495989,\n",
       " 0.004641941748559475,\n",
       " 0.0001572745240991935,\n",
       " -0.0007175357895903289,\n",
       " 0.014372030273079872,\n",
       " 0.004633183125406504,\n",
       " 0.0061473846435546875,\n",
       " -0.0021686251275241375,\n",
       " -0.004770617466419935,\n",
       " -0.0009008366032503545,\n",
       " -0.002459073904901743,\n",
       " 0.002640968654304743,\n",
       " -0.0038491557352244854,\n",
       " 0.003676890628412366,\n",
       " -0.0023261122405529022,\n",
       " -0.0004523353127297014,\n",
       " -0.005562697071582079,\n",
       " -0.004982482176274061,\n",
       " 8.824718679534271e-05,\n",
       " 0.0015076041454449296,\n",
       " 0.009197380393743515,\n",
       " 0.012645277194678783,\n",
       " -0.010137747973203659,\n",
       " 0.0009902367601171136,\n",
       " -0.00522357365116477,\n",
       " 0.024557506665587425,\n",
       " -0.0043695103377103806,\n",
       " -0.014269108884036541,\n",
       " -0.016807585954666138,\n",
       " 0.004672529641538858,\n",
       " -0.001971447141841054,\n",
       " -0.0011268213856965303,\n",
       " 0.006927594542503357,\n",
       " 0.003063152777031064,\n",
       " 0.0025615079794079065,\n",
       " 0.002719832118600607,\n",
       " -0.0020583290606737137,\n",
       " 0.0004261560388840735,\n",
       " -0.005319574382156134,\n",
       " -0.006699011195451021,\n",
       " 0.052522316575050354,\n",
       " -0.005500569939613342,\n",
       " 0.00092098000459373,\n",
       " -0.008647406473755836,\n",
       " -0.03424210101366043,\n",
       " -0.003644106909632683,\n",
       " -0.009931432083249092,\n",
       " -0.002009359188377857,\n",
       " -0.008200345560908318,\n",
       " -0.005600797012448311,\n",
       " -0.0028678621165454388,\n",
       " -0.004693689290434122,\n",
       " 0.004546703305095434,\n",
       " -0.0013933638110756874,\n",
       " -0.01346726343035698,\n",
       " -0.0004452885768841952,\n",
       " 0.006491399835795164,\n",
       " -0.003954652696847916,\n",
       " 0.010777720250189304,\n",
       " 0.004697864409536123,\n",
       " -0.006632684264332056,\n",
       " 0.005837645847350359,\n",
       " -0.0010713022202253342,\n",
       " 0.007804456166923046,\n",
       " 0.0024659987539052963,\n",
       " 0.005295366048812866,\n",
       " -0.0029289843514561653,\n",
       " 0.002091802190989256,\n",
       " -0.0022670766338706017,\n",
       " 0.005781135521829128,\n",
       " 9.407920151716098e-05,\n",
       " -0.005149293690919876,\n",
       " -0.00259595038369298,\n",
       " -0.002027335576713085,\n",
       " 0.0028998604975640774,\n",
       " -0.0012940845917910337,\n",
       " -0.0027414518408477306,\n",
       " 0.008695012889802456,\n",
       " 0.006967633031308651,\n",
       " -0.002456000307574868,\n",
       " 0.001946290023624897,\n",
       " 0.003198507009074092,\n",
       " 0.0017662746831774712,\n",
       " -0.004945914261043072,\n",
       " 0.0016292696818709373,\n",
       " 0.006138690281659365,\n",
       " 0.005735797341912985,\n",
       " 0.0489894263446331,\n",
       " 0.0027504211757332087,\n",
       " 0.001414884114637971,\n",
       " -0.0032148256432265043,\n",
       " -0.007304660510271788,\n",
       " -0.0021468664053827524,\n",
       " 0.005270328372716904,\n",
       " 0.008782788179814816,\n",
       " 0.005249622743576765,\n",
       " 0.005948175676167011,\n",
       " -0.007810202892869711,\n",
       " -0.0036756626795977354,\n",
       " 0.008181489072740078,\n",
       " 0.001121930661611259,\n",
       " 0.0040994370356202126,\n",
       " -0.0025397618301212788,\n",
       " 0.004154886119067669,\n",
       " -0.0028718451503664255,\n",
       " -0.007622947450727224,\n",
       " 0.005248549859970808,\n",
       " 0.007796888705343008,\n",
       " 0.012447189539670944,\n",
       " -0.004435124807059765,\n",
       " 0.002443385310471058,\n",
       " 0.002333434298634529,\n",
       " 0.012262007221579552,\n",
       " 0.012986174784600735,\n",
       " 0.004730907268822193,\n",
       " -0.00027673138538375497,\n",
       " -0.006026193965226412,\n",
       " -0.0024297607596963644,\n",
       " 0.002481736009940505,\n",
       " 0.0013480086345225573,\n",
       " 0.047603435814380646,\n",
       " 0.004682531114667654,\n",
       " 0.0020347540266811848,\n",
       " 0.009860155172646046,\n",
       " 0.0034139568451792,\n",
       " 0.005092184524983168,\n",
       " 0.008724217303097248,\n",
       " 0.0065621365793049335,\n",
       " -0.008540680631995201,\n",
       " -0.005187490489333868,\n",
       " -0.006248192396014929,\n",
       " 0.007178571540862322,\n",
       " -0.0014309885445982218,\n",
       " -0.007358389440923929,\n",
       " 0.003462418681010604,\n",
       " -0.002985323779284954,\n",
       " 0.0015459568239748478,\n",
       " -0.011265705339610577,\n",
       " 0.007943427190184593,\n",
       " 0.012561568059027195,\n",
       " -0.0018212673021480441,\n",
       " -0.002224670024588704,\n",
       " -0.005145045462995768,\n",
       " -0.001875042449682951,\n",
       " -2.987835614476353e-05,\n",
       " 0.002541439840570092,\n",
       " 0.0005148680065758526,\n",
       " -0.008181567303836346,\n",
       " 0.0059842877089977264,\n",
       " -0.0028666506987065077,\n",
       " -0.000841955654323101,\n",
       " -0.005881947930902243,\n",
       " 0.012864099815487862,\n",
       " -0.008458487689495087,\n",
       " -0.00796215794980526,\n",
       " 0.007489658892154694,\n",
       " -0.0005763947265222669,\n",
       " 0.005935813300311565,\n",
       " 0.004039907827973366,\n",
       " 0.03028891608119011,\n",
       " -0.0004233892832417041,\n",
       " -0.0034225014969706535,\n",
       " -0.005473567638546228,\n",
       " -0.0020671705715358257,\n",
       " 0.0048046475276350975,\n",
       " 0.0068342722952365875,\n",
       " 0.004323914181441069,\n",
       " -0.007464045193046331,\n",
       " 0.0028812747914344072,\n",
       " -0.013592159375548363,\n",
       " -0.01876094564795494,\n",
       " -0.002003823406994343,\n",
       " -0.011021856218576431,\n",
       " -0.00026500679086893797,\n",
       " -0.015745410695672035,\n",
       " -0.011789892800152302,\n",
       " 0.0026315664872527122,\n",
       " -0.009905458427965641,\n",
       " 0.010289406403899193,\n",
       " 0.013434004038572311,\n",
       " 0.00035754498094320297,\n",
       " -0.004599090199917555,\n",
       " -0.0016203952254727483,\n",
       " -0.005342663265764713,\n",
       " 0.0027931109070777893,\n",
       " 0.005723138339817524,\n",
       " 0.004107479937374592,\n",
       " -0.0014080710243433714,\n",
       " -0.005759018938988447,\n",
       " 0.00482203159481287,\n",
       " 0.007962265983223915,\n",
       " 0.00034714810317382216,\n",
       " 0.0020149059128016233,\n",
       " 0.0018992077093571424,\n",
       " -0.004896746948361397,\n",
       " -0.0013220006367191672,\n",
       " -0.006246404722332954,\n",
       " 0.0015243185916915536,\n",
       " -0.006641885731369257,\n",
       " 0.00931522622704506,\n",
       " 0.010963871143758297,\n",
       " -0.0033257908653467894,\n",
       " -0.008566106669604778,\n",
       " -0.009642982855439186,\n",
       " 0.011144403368234634,\n",
       " 0.0018178230384364724,\n",
       " -0.0008592515951022506,\n",
       " -0.021921813488006592,\n",
       " 0.009820155799388885,\n",
       " -0.010535073466598988,\n",
       " 0.0016491295536980033,\n",
       " 0.002504197647795081,\n",
       " 0.0072646732442080975,\n",
       " -0.003628181293606758,\n",
       " -0.005646285135298967,\n",
       " -0.012499009259045124,\n",
       " -0.009678017348051071,\n",
       " 0.0028058530297130346,\n",
       " -0.012624415569007397,\n",
       " -0.004102047067135572,\n",
       " 0.0006727742729708552,\n",
       " 0.013805671595036983,\n",
       " -0.006431232206523418,\n",
       " -0.008867925964295864,\n",
       " -0.004885554779320955,\n",
       " 0.009367533028125763,\n",
       " 0.011965682730078697,\n",
       " -0.002002920024096966,\n",
       " -0.004715254995971918,\n",
       " 0.00792788714170456,\n",
       " -0.003066255943849683,\n",
       " -0.00887142214924097,\n",
       " -0.0029375648591667414,\n",
       " -0.003986936062574387,\n",
       " -0.0026436024345457554,\n",
       " 0.007476825267076492,\n",
       " 0.006399740930646658,\n",
       " -0.006828857120126486,\n",
       " 0.00873886700719595,\n",
       " 0.0020421347580850124,\n",
       " 0.0006992446724325418,\n",
       " 0.006475119851529598,\n",
       " 0.0013181983958929777,\n",
       " 0.00736279459670186,\n",
       " 0.020361173897981644,\n",
       " -0.0016117674531415105,\n",
       " -0.006790739018470049,\n",
       " -0.005763167981058359,\n",
       " 0.009073585271835327,\n",
       " -0.0011500754626467824,\n",
       " -0.0013993929605931044,\n",
       " -0.012712931260466576,\n",
       " 0.0011678114533424377,\n",
       " -0.008311527781188488,\n",
       " -0.007741186767816544,\n",
       " -0.006256681401282549,\n",
       " -0.007424075622111559,\n",
       " 0.0026157591491937637,\n",
       " 0.0060938443057239056,\n",
       " -0.0011928221210837364,\n",
       " 0.004855483770370483,\n",
       " -0.007922768592834473,\n",
       " 0.007031840737909079,\n",
       " -0.006323647685348988,\n",
       " ...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"REASON FOR STUDY:  Seizures. CLINICAL HISTORY:  A 34-year-old woman with a history of seizures as well as kidney disease with  last one 2 months. MEDICATIONS:  Lipitor, Lamictal. INTRODUCTION:  A routine EEG was performed using the standard 10-20 electrode placement system with the addition of anterior temporal and single lead EKG electrode.  The patient was recorded during wakefulness and drowsiness with activating procedures including hyperventilation and photic stimulation. TECHNICAL DIFFICULTIES:  None. DESCRIPTION OF THE RECORD:  The record opens to a well-defined posterior dominant rhythm that reaches 9 Hz, which is reactive to eye opening.  There is normal frontocentral beta.  The patient was recorded during wakefulness and stage 1 sleep.  Activating procedures including  hyperventilation and photic stimulation produced no abnormal discharges. ABNORMAL DISCHARGES:  None. HEART RATE:  60. IMPRESSION:  Normal awake and sleep EEG. CLINICAL CORRELATION:  This is a normal awake and sleep EEG.  No seizures or epileptiform discharges were seen.\"\n",
    "\n",
    "sentence_embedder(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_embeddings = []\n",
    "for r in report_df['report']:\n",
    "        emb = sentence_embedder(r)\n",
    "        report_embeddings.append(emb)\n",
    "\n",
    "report_embeddings = np.array(report_embeddings)\n",
    "report_df['embs_instructor'] = report_embeddings.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_df.to_csv(\"report_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GET DATA FOR EACH RECORDING\n",
    "\"\"\"\n",
    "TUHAbnormal_PATH = '/home/jovyan/mne_data/TUH/tuh_eeg_abnormal/v2.0.0'\n",
    "N_JOBS = 8  # specify the number of jobs for loading and windowing\n",
    "\n",
    "\n",
    "tuh = TUHAbnormal(\n",
    "    path=TUHAbnormal_PATH,\n",
    "    recording_ids=None,\n",
    "    target_name=('report','pathological','gender','age'),\n",
    "    preload=False,\n",
    "    add_physician_reports=True,\n",
    "    n_jobs=N_JOBS, \n",
    ")\n",
    "\n",
    "tuh_subjects = tuh.split('subject')\n",
    "key_list = list(tuh_subjects.keys())\n",
    "report_df = pd.DataFrame(columns=('report', 'pathological', 'gender', 'age'))\n",
    "for i in range(len(key_list)):\n",
    "   report_df.loc[i] = tuh_subjects[key_list[i]][0][1]\n",
    "\n",
    "report_df.to_csv(\"report_df.csv\")\n",
    "\"\"\"\n",
    "### GET EMBEDDINGS FOR THE REPORT COLUMN\n",
    "\"\"\"\n",
    "report_df = pd.read_csv(\"report_df.csv\")\n",
    "report_embeddings = []\n",
    "for r in report_df['report']:\n",
    "        emb = sentence_embedder(r)\n",
    "        report_embeddings.append(emb)\n",
    "\n",
    "report_embeddings = np.array(report_embeddings)\n",
    "report_df['embs_bert'] = report_embeddings.tolist()\n",
    "\n",
    "report_df.to_csv(\"report_df.csv\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs_name = \"embs_instructor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_368/2805716872.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  report_df[embs_name][r] = re\n"
     ]
    }
   ],
   "source": [
    "report_df = pd.read_csv(\"report_df.csv\")\n",
    "\n",
    "# convert the report embeddings from string to array\n",
    "import copy\n",
    "for r in range(len(report_df)):\n",
    "    re = copy.copy(report_df[embs_name][r])\n",
    "    # convert the string to array\n",
    "    re = re.replace('[', '')\n",
    "    re = re.replace(']', '')\n",
    "    re = re.replace(',', '')\n",
    "    re = re.split()\n",
    "    re = [float(i) for i in re]\n",
    "    report_df[embs_name][r] = re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "report\n",
       "False    1546\n",
       "True      783\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# distribution of the report column\n",
    "# count \"epilep\" in the report column. Among those, exclude the ones with \"no epilep\"\n",
    "report_df['report'].str.lower().str.contains('epilep').value_counts()\n",
    "report_df['report'].str.lower().str.contains('no epilep').value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new column detecting if the report contains the word \"seizure\" Must filter out \"no seizure\"\n",
    "report_df['seizure'] = report_df['report'].str.contains('seizure', case=False)\n",
    "report_df['seizure'] = report_df['seizure'] & ~report_df['report'].str.contains('no seizure', case=False)\n",
    "\n",
    "# new column detecting if the report contains the word \"epilep\". Must filter out \"no epilep\"\n",
    "report_df['epilep'] = report_df['report'].str.contains('epilep', case=False)\n",
    "report_df['epilep'] = report_df['epilep'] & ~report_df['report'].str.contains('no epilep', case=False)\n",
    "# medication list \n",
    "medication_list = [\"keppra\", \"dilantin\", \"depakote\"]\n",
    "# new column detecting if the report contains one or more medications\n",
    "report_df['medication'] = report_df['report'].str.contains('|'.join(medication_list), case=False)\n",
    "\n",
    "# convert the 'gender' column to 0 and 1\n",
    "report_df['gender'].replace({'M': 0, 'F': 1}, inplace=True)\n",
    "\n",
    "# new column under_50 detecting if the age is under 50\n",
    "report_df['under_50'] = report_df['age'] < 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balance of classes in train set:  0.46484165324745036\n",
      "balance of classes in test set:  0.45493562231759654\n",
      "Accuracy:  0.763612390432328\n"
     ]
    }
   ],
   "source": [
    "# decode category from embeddings using logistic regression\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "\n",
    "X = np.asarray(report_df[embs_name].values.tolist())\n",
    "y = report_df[\"seizure\"].values\n",
    "\n",
    "\n",
    "model = LogisticRegression()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2)\n",
    "print(\"balance of classes in train set: \", np.mean(y_train))\n",
    "print(\"balance of classes in test set: \", np.mean(y_test))\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy: \", balanced_accuracy_score(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_df[\"embs_instructor\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using distance (cosine similarity) to classify reports\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "field = \"pathological\"\n",
    "s0 = \"This is a normal recording. \"\n",
    "s1 = \"This is an abnormal recording. \"\n",
    "\n",
    "field = \"medication\"\n",
    "s0 = \"no anti-epileptic drugs were prescribed to the patient\" #\"The patient is unlikely to have been prescribed anti-epileptic drugs (anticonvulsants, keppra, dilantin or depakote), used to control seizures\"  #\"keppra\", \"dilantin\", \"depakote\"\n",
    "s1 = \"anti-epileptic drugs medication was prescribed to the patient\" #\"The patient is likely to have been prescribed anti-epileptic drugs (anticonvulsants, keppra, dilantin or depakote), used to control seizures\"  #\"keppra, dilantin or depakote\" \n",
    "\n",
    "\n",
    "field = \"seizure\"\n",
    "s0 = \"The patient is very unlikely to be subject to seizures\"\n",
    "s1 = \"The patient is very likely to be subject to seizures\"\n",
    "\n",
    "\n",
    "field = \"under_50\"\n",
    "s0 = \"The patient is over 50 year old\"\n",
    "s1 = \"The patient is under 50 year old\"\n",
    "\n",
    "field = \"gender\"\n",
    "s0 = \"The patient is male\"\n",
    "s1 = \"The patient is female\"\n",
    "\n",
    "\n",
    "field = \"epilep\"\n",
    "s0 = \"The patient does not have epilepsy\"\n",
    "s1 = \"The patient has epilepsy\"\n",
    "\n",
    "s0_embed = sentence_embedder(s0)\n",
    "s1_embed = sentence_embedder(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "### find typical sentence for each class by doing the mean of the embeddings of the sentences in the class\n",
    "field = \"medication\"\n",
    "s0_embed = np.mean(report_df[report_df[field] == 0][embs_name].values.tolist(), axis=0)\n",
    "s1_embed = np.mean(report_df[report_df[field] == 1][embs_name].values.tolist(), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label balance : 0.42765135251180764\n",
      "Accuracy:  0.7277086493490077\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial import distance\n",
    "# classify each report as either s0 or s1\n",
    "distance_classifier = []\n",
    "for r in report_df[embs_name]:\n",
    "    d0 = distance.cosine(r, s0_embed)\n",
    "    d1 = distance.cosine(r, s1_embed)\n",
    "    if d0 < d1:\n",
    "        distance_classifier.append(0)\n",
    "    else:\n",
    "        distance_classifier.append(1)\n",
    "\n",
    "print(\"label balance :\", np.mean(distance_classifier))\n",
    "\n",
    "# compare to the actual labels\n",
    "print(\"Accuracy: \", balanced_accuracy_score(report_df[field], distance_classifier))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 15\u001b[0m\n\u001b[1;32m     11\u001b[0m model \u001b[39m=\u001b[39m MLPRegressor(random_state\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, max_iter\u001b[39m=\u001b[39m\u001b[39m500\u001b[39m)\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     14\u001b[0m \u001b[39m# using xgboost\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mxgboost\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mxgb\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39m#model = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.1,\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[39m#                max_depth = 5, alpha = 10, n_estimators = 10)\u001b[39;00m\n\u001b[1;32m     19\u001b[0m y \u001b[39m=\u001b[39m report_df[\u001b[39m\"\u001b[39m\u001b[39mage\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mvalues\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "# decode age from embeddings using linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#model = LinearRegression()\n",
    "\n",
    "# using a mlp\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "model = MLPRegressor(random_state=1, max_iter=500).fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# using xgboost\n",
    "import xgboost as xgb\n",
    "#model = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "#                max_depth = 5, alpha = 10, n_estimators = 10)\n",
    "\n",
    "y = report_df[\"age\"].values\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.33, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"MSE: \", mean_squared_error(y_test, y_pred))\n",
    "# average age error\n",
    "print(\"MAE: \", np.mean(np.abs(y_test - y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot predicted age vs. true age\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel(\"True Age\")\n",
    "plt.ylabel(\"Predicted Age\")\n",
    "# set xmin and xmax to the same value to make the plot square\n",
    "plt.xlim(0, 100)\n",
    "plt.ylim(0, 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|| 1.52k/1.52k [00:00<00:00, 558kB/s]\n",
      "Downloading: 100%|| 4.96G/4.96G [01:45<00:00, 47.0MB/s]\n",
      "Some weights of T5Model were not initialized from the model checkpoint at hkunlp/instructor-xl and are newly initialized: ['decoder.block.4.layer.2.layer_norm.weight', 'decoder.block.23.layer.1.EncDecAttention.v.weight', 'decoder.block.0.layer.2.DenseReluDense.wo.weight', 'decoder.block.12.layer.1.EncDecAttention.k.weight', 'decoder.block.20.layer.2.DenseReluDense.wi.weight', 'decoder.block.2.layer.2.DenseReluDense.wo.weight', 'decoder.block.15.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.1.EncDecAttention.v.weight', 'decoder.block.2.layer.0.SelfAttention.q.weight', 'decoder.block.14.layer.0.SelfAttention.k.weight', 'decoder.block.9.layer.2.DenseReluDense.wi.weight', 'decoder.block.14.layer.1.layer_norm.weight', 'decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'decoder.block.21.layer.1.EncDecAttention.v.weight', 'decoder.block.4.layer.1.EncDecAttention.k.weight', 'decoder.block.8.layer.0.layer_norm.weight', 'decoder.block.7.layer.0.layer_norm.weight', 'decoder.block.10.layer.1.EncDecAttention.q.weight', 'decoder.block.0.layer.0.SelfAttention.o.weight', 'decoder.block.4.layer.2.DenseReluDense.wi.weight', 'decoder.block.4.layer.0.SelfAttention.o.weight', 'decoder.block.6.layer.0.SelfAttention.k.weight', 'decoder.block.4.layer.0.SelfAttention.q.weight', 'decoder.block.13.layer.0.layer_norm.weight', 'decoder.block.14.layer.0.SelfAttention.v.weight', 'decoder.block.9.layer.1.EncDecAttention.o.weight', 'decoder.block.2.layer.2.DenseReluDense.wi.weight', 'decoder.block.1.layer.1.EncDecAttention.o.weight', 'decoder.block.0.layer.2.layer_norm.weight', 'decoder.block.21.layer.1.EncDecAttention.k.weight', 'decoder.block.5.layer.0.SelfAttention.v.weight', 'decoder.block.5.layer.1.EncDecAttention.q.weight', 'decoder.block.23.layer.0.SelfAttention.k.weight', 'decoder.block.12.layer.1.EncDecAttention.v.weight', 'decoder.block.1.layer.2.layer_norm.weight', 'decoder.block.14.layer.1.EncDecAttention.q.weight', 'decoder.block.9.layer.2.layer_norm.weight', 'decoder.block.0.layer.2.DenseReluDense.wi.weight', 'decoder.block.15.layer.2.DenseReluDense.wo.weight', 'decoder.block.18.layer.1.EncDecAttention.v.weight', 'decoder.block.0.layer.0.layer_norm.weight', 'decoder.block.22.layer.1.layer_norm.weight', 'decoder.block.19.layer.0.SelfAttention.v.weight', 'decoder.block.1.layer.1.EncDecAttention.q.weight', 'decoder.block.23.layer.1.EncDecAttention.o.weight', 'decoder.block.21.layer.2.DenseReluDense.wo.weight', 'decoder.block.17.layer.1.EncDecAttention.v.weight', 'decoder.block.19.layer.1.EncDecAttention.q.weight', 'decoder.block.12.layer.2.layer_norm.weight', 'decoder.block.7.layer.2.DenseReluDense.wi.weight', 'decoder.block.14.layer.1.EncDecAttention.v.weight', 'decoder.block.13.layer.1.layer_norm.weight', 'decoder.block.6.layer.1.EncDecAttention.v.weight', 'decoder.block.22.layer.0.SelfAttention.o.weight', 'decoder.block.7.layer.1.EncDecAttention.q.weight', 'decoder.block.3.layer.1.EncDecAttention.q.weight', 'decoder.block.5.layer.2.DenseReluDense.wo.weight', 'decoder.block.13.layer.2.DenseReluDense.wi.weight', 'decoder.block.0.layer.0.SelfAttention.k.weight', 'decoder.block.17.layer.2.DenseReluDense.wo.weight', 'decoder.block.9.layer.1.EncDecAttention.v.weight', 'decoder.block.16.layer.0.layer_norm.weight', 'decoder.block.2.layer.1.layer_norm.weight', 'decoder.block.10.layer.0.SelfAttention.q.weight', 'decoder.block.19.layer.2.DenseReluDense.wo.weight', 'decoder.block.2.layer.0.SelfAttention.k.weight', 'decoder.block.8.layer.0.SelfAttention.v.weight', 'decoder.block.6.layer.1.EncDecAttention.o.weight', 'decoder.block.8.layer.2.DenseReluDense.wi.weight', 'decoder.block.13.layer.0.SelfAttention.v.weight', 'decoder.block.1.layer.0.SelfAttention.q.weight', 'decoder.block.13.layer.1.EncDecAttention.q.weight', 'decoder.block.2.layer.1.EncDecAttention.q.weight', 'decoder.block.8.layer.1.EncDecAttention.k.weight', 'decoder.block.2.layer.0.layer_norm.weight', 'decoder.block.3.layer.0.SelfAttention.v.weight', 'decoder.block.2.layer.1.EncDecAttention.k.weight', 'decoder.block.6.layer.0.SelfAttention.q.weight', 'decoder.block.17.layer.1.layer_norm.weight', 'decoder.block.15.layer.2.DenseReluDense.wi.weight', 'decoder.block.5.layer.0.SelfAttention.o.weight', 'decoder.block.3.layer.1.EncDecAttention.k.weight', 'decoder.block.14.layer.1.EncDecAttention.k.weight', 'decoder.block.20.layer.1.layer_norm.weight', 'decoder.block.16.layer.1.EncDecAttention.o.weight', 'decoder.block.12.layer.1.layer_norm.weight', 'decoder.block.12.layer.0.SelfAttention.q.weight', 'decoder.block.2.layer.0.SelfAttention.v.weight', 'decoder.block.12.layer.0.SelfAttention.o.weight', 'decoder.block.16.layer.2.DenseReluDense.wi.weight', 'decoder.block.0.layer.0.SelfAttention.v.weight', 'decoder.block.10.layer.1.EncDecAttention.k.weight', 'decoder.block.21.layer.0.SelfAttention.v.weight', 'decoder.block.1.layer.0.SelfAttention.k.weight', 'decoder.block.5.layer.2.layer_norm.weight', 'decoder.block.20.layer.0.SelfAttention.v.weight', 'decoder.block.11.layer.1.EncDecAttention.v.weight', 'decoder.block.17.layer.0.SelfAttention.k.weight', 'decoder.block.15.layer.0.SelfAttention.k.weight', 'decoder.block.19.layer.1.EncDecAttention.o.weight', 'decoder.block.9.layer.1.EncDecAttention.k.weight', 'decoder.block.10.layer.2.layer_norm.weight', 'decoder.block.22.layer.2.DenseReluDense.wi.weight', 'decoder.block.11.layer.2.layer_norm.weight', 'decoder.block.10.layer.1.layer_norm.weight', 'decoder.block.8.layer.2.DenseReluDense.wo.weight', 'decoder.block.23.layer.1.EncDecAttention.k.weight', 'decoder.block.14.layer.2.DenseReluDense.wo.weight', 'decoder.block.6.layer.1.layer_norm.weight', 'decoder.block.17.layer.1.EncDecAttention.k.weight', 'decoder.block.20.layer.0.SelfAttention.o.weight', 'decoder.block.6.layer.2.layer_norm.weight', 'decoder.block.5.layer.1.EncDecAttention.v.weight', 'decoder.block.2.layer.1.EncDecAttention.o.weight', 'decoder.block.10.layer.0.SelfAttention.o.weight', 'decoder.block.19.layer.0.layer_norm.weight', 'decoder.block.0.layer.1.EncDecAttention.k.weight', 'decoder.block.9.layer.0.SelfAttention.k.weight', 'decoder.block.7.layer.1.EncDecAttention.k.weight', 'decoder.block.14.layer.0.SelfAttention.q.weight', 'decoder.block.18.layer.2.DenseReluDense.wi.weight', 'decoder.block.17.layer.0.SelfAttention.v.weight', 'decoder.block.8.layer.0.SelfAttention.q.weight', 'decoder.block.9.layer.1.layer_norm.weight', 'decoder.block.17.layer.2.layer_norm.weight', 'decoder.block.2.layer.0.SelfAttention.o.weight', 'decoder.block.16.layer.1.EncDecAttention.k.weight', 'decoder.block.11.layer.0.SelfAttention.q.weight', 'decoder.block.5.layer.0.SelfAttention.k.weight', 'decoder.block.1.layer.1.EncDecAttention.v.weight', 'decoder.block.6.layer.2.DenseReluDense.wo.weight', 'decoder.block.21.layer.2.layer_norm.weight', 'decoder.block.15.layer.2.layer_norm.weight', 'decoder.block.9.layer.0.SelfAttention.q.weight', 'decoder.block.14.layer.0.SelfAttention.o.weight', 'decoder.block.22.layer.0.SelfAttention.v.weight', 'decoder.block.14.layer.0.layer_norm.weight', 'decoder.block.10.layer.2.DenseReluDense.wo.weight', 'decoder.block.10.layer.0.SelfAttention.v.weight', 'decoder.block.15.layer.0.layer_norm.weight', 'decoder.block.19.layer.2.DenseReluDense.wi.weight', 'decoder.block.18.layer.1.EncDecAttention.q.weight', 'decoder.block.12.layer.2.DenseReluDense.wo.weight', 'decoder.block.1.layer.2.DenseReluDense.wo.weight', 'decoder.block.13.layer.2.layer_norm.weight', 'decoder.block.22.layer.1.EncDecAttention.o.weight', 'decoder.block.12.layer.0.layer_norm.weight', 'decoder.block.20.layer.1.EncDecAttention.q.weight', 'decoder.block.9.layer.0.SelfAttention.o.weight', 'decoder.block.10.layer.2.DenseReluDense.wi.weight', 'decoder.block.23.layer.2.layer_norm.weight', 'decoder.block.9.layer.0.SelfAttention.v.weight', 'decoder.block.11.layer.2.DenseReluDense.wo.weight', 'decoder.block.13.layer.1.EncDecAttention.k.weight', 'decoder.block.21.layer.0.SelfAttention.q.weight', 'decoder.block.11.layer.0.SelfAttention.v.weight', 'decoder.block.8.layer.2.layer_norm.weight', 'decoder.block.4.layer.1.EncDecAttention.v.weight', 'decoder.block.11.layer.1.EncDecAttention.q.weight', 'decoder.block.4.layer.1.EncDecAttention.o.weight', 'decoder.block.23.layer.0.SelfAttention.o.weight', 'decoder.block.17.layer.0.layer_norm.weight', 'decoder.block.16.layer.1.EncDecAttention.q.weight', 'decoder.block.20.layer.0.SelfAttention.q.weight', 'decoder.block.6.layer.0.layer_norm.weight', 'decoder.block.3.layer.1.EncDecAttention.o.weight', 'decoder.block.12.layer.0.SelfAttention.k.weight', 'decoder.block.11.layer.1.layer_norm.weight', 'decoder.block.7.layer.2.DenseReluDense.wo.weight', 'decoder.block.8.layer.0.SelfAttention.k.weight', 'decoder.block.18.layer.2.layer_norm.weight', 'decoder.block.21.layer.0.SelfAttention.o.weight', 'decoder.block.20.layer.2.layer_norm.weight', 'decoder.final_layer_norm.weight', 'decoder.block.4.layer.0.SelfAttention.k.weight', 'decoder.block.22.layer.2.DenseReluDense.wo.weight', 'decoder.block.6.layer.1.EncDecAttention.q.weight', 'decoder.block.16.layer.0.SelfAttention.q.weight', 'decoder.block.2.layer.1.EncDecAttention.v.weight', 'decoder.block.18.layer.1.EncDecAttention.k.weight', 'decoder.block.0.layer.1.layer_norm.weight', 'decoder.block.23.layer.1.layer_norm.weight', 'decoder.block.13.layer.0.SelfAttention.o.weight', 'decoder.block.11.layer.2.DenseReluDense.wi.weight', 'decoder.block.3.layer.0.SelfAttention.q.weight', 'decoder.block.16.layer.0.SelfAttention.o.weight', 'decoder.block.11.layer.0.layer_norm.weight', 'decoder.block.15.layer.0.SelfAttention.q.weight', 'decoder.block.12.layer.2.DenseReluDense.wi.weight', 'decoder.block.14.layer.2.DenseReluDense.wi.weight', 'decoder.block.10.layer.0.layer_norm.weight', 'decoder.block.0.layer.1.EncDecAttention.o.weight', 'decoder.block.13.layer.2.DenseReluDense.wo.weight', 'decoder.block.14.layer.2.layer_norm.weight', 'decoder.block.7.layer.0.SelfAttention.v.weight', 'decoder.block.13.layer.1.EncDecAttention.o.weight', 'decoder.block.4.layer.0.layer_norm.weight', 'decoder.block.20.layer.2.DenseReluDense.wo.weight', 'decoder.block.19.layer.1.EncDecAttention.k.weight', 'decoder.block.7.layer.2.layer_norm.weight', 'decoder.block.9.layer.1.EncDecAttention.q.weight', 'decoder.block.15.layer.1.EncDecAttention.o.weight', 'decoder.block.17.layer.2.DenseReluDense.wi.weight', 'decoder.block.0.layer.0.SelfAttention.q.weight', 'decoder.block.17.layer.0.SelfAttention.o.weight', 'decoder.block.9.layer.0.layer_norm.weight', 'decoder.block.17.layer.1.EncDecAttention.o.weight', 'decoder.block.13.layer.1.EncDecAttention.v.weight', 'decoder.block.15.layer.1.EncDecAttention.k.weight', 'decoder.block.12.layer.1.EncDecAttention.q.weight', 'decoder.block.12.layer.1.EncDecAttention.o.weight', 'decoder.block.4.layer.2.DenseReluDense.wo.weight', 'decoder.block.5.layer.1.EncDecAttention.o.weight', 'decoder.block.11.layer.0.SelfAttention.o.weight', 'decoder.block.1.layer.1.EncDecAttention.k.weight', 'decoder.block.3.layer.2.DenseReluDense.wo.weight', 'decoder.block.23.layer.0.SelfAttention.v.weight', 'decoder.block.11.layer.1.EncDecAttention.o.weight', 'decoder.block.19.layer.0.SelfAttention.o.weight', 'decoder.block.16.layer.2.DenseReluDense.wo.weight', 'decoder.block.5.layer.1.EncDecAttention.k.weight', 'decoder.block.23.layer.0.SelfAttention.q.weight', 'decoder.block.22.layer.1.EncDecAttention.k.weight', 'decoder.block.18.layer.0.SelfAttention.o.weight', 'decoder.block.16.layer.2.layer_norm.weight', 'decoder.block.7.layer.1.layer_norm.weight', 'decoder.block.11.layer.1.EncDecAttention.k.weight', 'decoder.block.16.layer.0.SelfAttention.k.weight', 'decoder.block.4.layer.1.EncDecAttention.q.weight', 'decoder.block.6.layer.2.DenseReluDense.wi.weight', 'decoder.block.22.layer.0.SelfAttention.q.weight', 'decoder.block.22.layer.0.layer_norm.weight', 'decoder.block.20.layer.1.EncDecAttention.o.weight', 'decoder.block.5.layer.1.layer_norm.weight', 'decoder.block.23.layer.0.layer_norm.weight', 'decoder.block.13.layer.0.SelfAttention.k.weight', 'decoder.block.3.layer.2.layer_norm.weight', 'decoder.block.10.layer.1.EncDecAttention.o.weight', 'decoder.block.16.layer.0.SelfAttention.v.weight', 'decoder.block.18.layer.0.layer_norm.weight', 'decoder.block.22.layer.1.EncDecAttention.v.weight', 'decoder.block.18.layer.2.DenseReluDense.wo.weight', 'decoder.block.16.layer.1.EncDecAttention.v.weight', 'decoder.block.19.layer.0.SelfAttention.k.weight', 'decoder.block.3.layer.0.SelfAttention.o.weight', 'decoder.block.15.layer.1.EncDecAttention.v.weight', 'decoder.block.7.layer.0.SelfAttention.q.weight', 'decoder.block.22.layer.1.EncDecAttention.q.weight', 'decoder.block.8.layer.1.EncDecAttention.o.weight', 'decoder.block.21.layer.0.layer_norm.weight', 'decoder.block.1.layer.0.layer_norm.weight', 'decoder.block.12.layer.0.SelfAttention.v.weight', 'decoder.block.3.layer.0.SelfAttention.k.weight', 'decoder.block.3.layer.1.EncDecAttention.v.weight', 'decoder.block.1.layer.0.SelfAttention.o.weight', 'decoder.block.6.layer.0.SelfAttention.v.weight', 'decoder.block.19.layer.1.layer_norm.weight', 'decoder.block.17.layer.1.EncDecAttention.q.weight', 'decoder.block.23.layer.2.DenseReluDense.wi.weight', 'decoder.block.9.layer.2.DenseReluDense.wo.weight', 'decoder.block.5.layer.0.SelfAttention.q.weight', 'decoder.block.1.layer.1.layer_norm.weight', 'decoder.block.20.layer.1.EncDecAttention.v.weight', 'decoder.block.4.layer.1.layer_norm.weight', 'decoder.block.3.layer.2.DenseReluDense.wi.weight', 'decoder.block.22.layer.2.layer_norm.weight', 'decoder.block.15.layer.0.SelfAttention.o.weight', 'decoder.block.21.layer.2.DenseReluDense.wi.weight', 'decoder.block.13.layer.0.SelfAttention.q.weight', 'decoder.block.7.layer.1.EncDecAttention.o.weight', 'decoder.block.6.layer.0.SelfAttention.o.weight', 'decoder.block.3.layer.1.layer_norm.weight', 'decoder.block.23.layer.1.EncDecAttention.q.weight', 'decoder.block.20.layer.0.SelfAttention.k.weight', 'decoder.block.20.layer.1.EncDecAttention.k.weight', 'decoder.block.15.layer.1.layer_norm.weight', 'decoder.block.8.layer.1.EncDecAttention.v.weight', 'decoder.block.4.layer.0.SelfAttention.v.weight', 'decoder.block.18.layer.0.SelfAttention.v.weight', 'decoder.block.7.layer.0.SelfAttention.k.weight', 'decoder.block.18.layer.0.SelfAttention.k.weight', 'decoder.block.19.layer.1.EncDecAttention.v.weight', 'decoder.block.1.layer.0.SelfAttention.v.weight', 'decoder.block.2.layer.2.layer_norm.weight', 'decoder.block.14.layer.1.EncDecAttention.o.weight', 'decoder.block.10.layer.1.EncDecAttention.v.weight', 'decoder.block.21.layer.0.SelfAttention.k.weight', 'decoder.block.7.layer.0.SelfAttention.o.weight', 'decoder.block.18.layer.1.layer_norm.weight', 'decoder.block.19.layer.2.layer_norm.weight', 'decoder.block.5.layer.2.DenseReluDense.wi.weight', 'decoder.block.17.layer.0.SelfAttention.q.weight', 'decoder.block.21.layer.1.EncDecAttention.o.weight', 'decoder.block.21.layer.1.layer_norm.weight', 'decoder.block.7.layer.1.EncDecAttention.v.weight', 'decoder.block.18.layer.1.EncDecAttention.o.weight', 'decoder.block.19.layer.0.SelfAttention.q.weight', 'decoder.block.8.layer.1.layer_norm.weight', 'decoder.block.8.layer.1.EncDecAttention.q.weight', 'decoder.block.21.layer.1.EncDecAttention.q.weight', 'decoder.block.11.layer.0.SelfAttention.k.weight', 'decoder.block.15.layer.1.EncDecAttention.q.weight', 'decoder.block.20.layer.0.layer_norm.weight', 'decoder.block.18.layer.0.SelfAttention.q.weight', 'decoder.block.16.layer.1.layer_norm.weight', 'decoder.block.8.layer.0.SelfAttention.o.weight', 'decoder.block.6.layer.1.EncDecAttention.k.weight', 'decoder.block.0.layer.1.EncDecAttention.q.weight', 'decoder.block.1.layer.2.DenseReluDense.wi.weight', 'decoder.block.22.layer.0.SelfAttention.k.weight', 'decoder.block.3.layer.0.layer_norm.weight', 'decoder.block.5.layer.0.layer_norm.weight', 'decoder.block.23.layer.2.DenseReluDense.wo.weight', 'decoder.block.10.layer.0.SelfAttention.k.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = AutoModel.from_pretrained(\"hkunlp/instructor-xl\")/\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"hkunlp/instructor-xl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "bert_model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "\"\"\"\n",
    "sentence = \"sauce\"\n",
    "desc_tokenized = tokenizer(sentence, return_tensors=\"pt\", max_length=512, truncation=True, padding='max_length')\n",
    "outputs = model.encoder(**desc_tokenized)\n",
    "emb = outputs.to_tuple()[0][0][0].detach().numpy().tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPastAndCrossAttentions(last_hidden_state=tensor([[[ 5.1890e-01,  1.2115e-01, -2.6725e-02,  ...,  7.7272e-02,\n",
       "           5.0293e-01, -3.4116e-01],\n",
       "         [ 7.1057e-02,  6.9810e-02, -4.7813e-02,  ...,  2.0375e-01,\n",
       "           1.1002e-01, -6.0529e-02],\n",
       "         [-1.2254e-01,  1.4338e-01,  9.5085e-02,  ...,  1.2603e-01,\n",
       "           5.8572e-01, -1.9992e-01],\n",
       "         ...,\n",
       "         [-1.2521e-01,  1.0445e-01, -7.1089e-02,  ..., -2.5637e-04,\n",
       "           3.1636e-01, -3.5995e-01],\n",
       "         [-1.2521e-01,  1.0445e-01, -7.1089e-02,  ..., -2.5637e-04,\n",
       "           3.1636e-01, -3.5995e-01],\n",
       "         [-1.2521e-01,  1.0445e-01, -7.1089e-02,  ..., -2.5637e-04,\n",
       "           3.1636e-01, -3.5995e-01]]], grad_fn=<MulBackward0>), past_key_values=None, hidden_states=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "097b7033baff6ef61c19d5e3b26d00f2edd9fddb86c25af544d86fb0636b8d9f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
